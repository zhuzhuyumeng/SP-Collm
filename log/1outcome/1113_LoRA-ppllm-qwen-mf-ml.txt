W1129 11:01:21.369570 30176 site-packages\torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
2025-11-29 11:01:21,381 [INFO] Building datasets...
2025-11-29 11:01:21,573 [INFO] Movie OOD datasets, max history length:10
2025-11-29 11:01:21,600 [INFO] Movie OOD datasets, max history length:10
2025-11-29 11:01:21,759 [INFO] Movie OOD datasets, max history length:10
2025-11-29 11:01:21,901 [INFO] 
=====  Running Parameters    =====
2025-11-29 11:01:21,902 [INFO] {
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_url": "env://",
    "distributed": false,
    "evaluate": false,
    "init_lr": 0.001,
    "iters_per_epoch": 50,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1000,
    "min_lr": 1e-05,
    "mode": "v2",
    "num_workers": 0,
    "output_dir": "Qwen/Qwen2.5-1.5rec_log/collm",
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "rec_pretrain",
    "test_splits": [
        "test",
        "valid",
        "test_warm",
        "test_cold"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "valid"
    ],
    "warmup_lr": 1e-05,
    "warmup_steps": 200,
    "weight_decay": 0.001,
    "world_size": 1
}
2025-11-29 11:01:21,902 [INFO] 
======  Dataset Attributes  ======
2025-11-29 11:01:21,902 [INFO] 
======== movie_ood =======
2025-11-29 11:01:21,902 [INFO] {
    "build_info": {
        "storage": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
    },
    "data_type": "default",
    "path": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
}
2025-11-29 11:01:21,902 [INFO] 
======  Model Attributes  ======
2025-11-29 11:01:21,903 [INFO] {
    "ans_type": "v2",
    "arch": "mini_gpt4rec_v2",
    "ckpt": "minigpt4/Qwen/Qwen2.5-1.5rec_log/collm/20251112212_best_tallrec/checkpoint_best.pth",
    "end_sym": "###",
    "freeze_lora": true,
    "freeze_proj": false,
    "freeze_rec": true,
    "item_num": -100,
    "llama_model": "Qwen/Qwen2-1.5B",
    "lora_config": {
        "alpha": 16,
        "dropout": 0.05,
        "r": 8,
        "target_modules": [
            "q_proj",
            "v_proj"
        ],
        "use_lora": true
    },
    "max_txt_len": 1024,
    "model_type": "pretrain_vicuna",
    "proj_drop": 0,
    "proj_mid_times": 10,
    "proj_token_num": 1,
    "prompt_path": "prompts/ppllm_movie.txt",
    "prompt_template": "{}",
    "rec_config": {
        "embedding_size": 256,
        "item_num": 3256,
        "pretrained_path": "collm-trained-models/my-collm-trained-models/mf_0912_ml1m_oodv2_best_model_d256lr-0.001wd0.0001.pth",
        "user_num": 839
    },
    "rec_model": "MF",
    "user_num": -100
}
2025-11-29 11:01:21,915 [INFO] freeze rec encoder
`torch_dtype` is deprecated! Use `dtype` instead!

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
binary_path: D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll
CUDA SETUP: Loading binary D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll...
Not using distributed mode
流行度计算完成: Top 20% 标记为热门(Level 2)，其余为长尾(Level 0)。
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\train data size: (33891, 7)
Movie OOD datasets, max history length: 10
流行度计算完成: Top 20% 标记为热门(Level 2)，其余为长尾(Level 0)。
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\valid_small data size: (5200, 7)
Movie OOD datasets, max history length: 10
流行度计算完成: Top 20% 标记为热门(Level 2)，其余为长尾(Level 0)。
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\test data size: (7331, 7)
Movie OOD datasets, max history length: 10
data dir: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\
正在计算全局流行度以进行偏见评估...
已计算 3087 个物品的流行度。总物品数为 3256。
正在将流行度数据注入评估任务...
runing MiniGPT4Rec_v2 ...... 
Loading Rec_model
### rec_encoder: MF
creat MF model, user num: 839 item num: 3256
successfully load the pretrained model......
freeze rec encoder
Loading Rec_model Done
Loading LLama model: Qwen/Qwen2-1.5B
Loading LLAMA Done
Setting Lora
Setting Lora Done
freeze lora...
type: <class 'int'> 10
Load 4 training prompts
Prompt List: 
['#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> (<Popularity>) with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> (<Popularity>) with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> (<Popularity>) with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> (<Popularity>) with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:']
Load MiniGPT4Rec Checkpoint: minigpt4/Qwen/Qwen2.5-1.5rec_log/collm/20251112212_best_tallrec/checkpoint_best.pth
loading message, msg.... 
 _IncompatibleKeys(missing_keys=['rec_encoder.user_embedding.weight', 'rec_encoder.item_embedding.weight', 'llama_model.base_model.model.model.embed_tokens.weight', 'llama_model.base_model.model.model.layers.0.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.0.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.0.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.0.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.0.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.0.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.0.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.0.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.0.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.0.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.0.input_layernorm.weight', 'llama_model.base_model.model.model.layers.0.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.1.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.1.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.1.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.1.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.1.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.1.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.1.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.1.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.1.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.1.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.1.input_layernorm.weight', 'llama_model.base_model.model.model.layers.1.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.2.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.2.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.2.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.2.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.2.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.2.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.2.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.2.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.2.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.2.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.2.input_layernorm.weight', 'llama_model.base_model.model.model.layers.2.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.3.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.3.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.3.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.3.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.3.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.3.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.3.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.3.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.3.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.3.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.3.input_layernorm.weight', 'llama_model.base_model.model.model.layers.3.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.4.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.4.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.4.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.4.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.4.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.4.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.4.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.4.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.4.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.4.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.4.input_layernorm.weight', 'llama_model.base_model.model.model.layers.4.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.5.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.5.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.5.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.5.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.5.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.5.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.5.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.5.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.5.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.5.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.5.input_layernorm.weight', 'llama_model.base_model.model.model.layers.5.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.6.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.6.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.6.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.6.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.6.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.6.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.6.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.6.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.6.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.6.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.6.input_layernorm.weight', 'llama_model.base_model.model.model.layers.6.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.7.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.7.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.7.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.7.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.7.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.7.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.7.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.7.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.7.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.7.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.7.input_layernorm.weight', 'llama_model.base_model.model.model.layers.7.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.8.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.8.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.8.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.8.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.8.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.8.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.8.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.8.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.8.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.8.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.8.input_layernorm.weight', 'llama_model.base_model.model.model.layers.8.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.9.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.9.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.9.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.9.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.9.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.9.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.9.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.9.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.9.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.9.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.9.input_layernorm.weight', 'llama_model.base_model.model.model.layers.9.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.10.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.10.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.10.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.10.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.10.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.10.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.10.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.10.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.10.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.10.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.10.input_layernorm.weight', 'llama_model.base_model.model.model.layers.10.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.11.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.11.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.11.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.11.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.11.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.11.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.11.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.11.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.11.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.11.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.11.input_layernorm.weight', 'llama_model.base_model.model.model.layers.11.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.12.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.12.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.12.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.12.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.12.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.12.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.12.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.12.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.12.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.12.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.12.input_layernorm.weight', 'llama_model.base_model.model.model.layers.12.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.13.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.13.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.13.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.13.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.13.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.13.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.13.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.13.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.13.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.13.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.13.input_layernorm.weight', 'llama_model.base_model.model.model.layers.13.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.14.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.14.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.14.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.14.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.14.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.14.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.14.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.14.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.14.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.14.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.14.input_layernorm.weight', 'llama_model.base_model.model.model.layers.14.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.15.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.15.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.15.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.15.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.15.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.15.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.15.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.15.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.15.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.15.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.15.input_layernorm.weight', 'llama_model.base_model.model.model.layers.15.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.16.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.16.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.16.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.16.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.16.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.16.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.16.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.16.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.16.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.16.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.16.input_layernorm.weight', 'llama_model.base_model.model.model.layers.16.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.17.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.17.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.17.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.17.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.17.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.17.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.17.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.17.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.17.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.17.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.17.input_layernorm.weight', 'llama_model.base_model.model.model.layers.17.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.18.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.18.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.18.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.18.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.18.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.18.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.18.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.18.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.18.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.18.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.18.input_layernorm.weight', 'llama_model.base_model.model.model.layers.18.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.19.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.19.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.19.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.19.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.19.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.19.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.19.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.19.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.19.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.19.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.19.input_layernorm.weight', 'llama_model.base_model.model.model.layers.19.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.20.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.20.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.20.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.20.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.20.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.20.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.20.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.20.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.20.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.20.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.20.input_layernorm.weight', 'llama_model.base_model.model.model.layers.20.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.21.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.21.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.21.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.21.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.21.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.21.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.21.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.21.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.21.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.21.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.21.input_layernorm.weight', 'llama_model.base_model.model.model.layers.21.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.22.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.22.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.22.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.22.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.22.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.22.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.22.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.22.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.22.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.22.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.22.input_layernorm.weight', 'llama_model.base_model.model.model.layers.22.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.23.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.23.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.23.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.23.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.23.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.23.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.23.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.23.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.23.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.23.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.23.input_layernorm.weight', 'llama_model.base_model.model.model.layers.23.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.24.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.24.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.24.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.24.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.24.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.24.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.24.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.24.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.24.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.24.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.24.input_layernorm.weight', 'llama_model.base_model.model.model.layers.24.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.25.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.25.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.25.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.25.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.25.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.25.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.25.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.25.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.25.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.25.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.25.input_layernorm.weight', 'llama_model.base_model.model.model.layers.25.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.26.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.26.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.26.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.26.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.26.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.26.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.26.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.26.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.26.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.26.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.26.input_layernorm.weight', 'llama_model.base_model.model.model.layers.26.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.27.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.27.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.27.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.27.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.27.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.27.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.27.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.27.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.27.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.27.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.27.input_layernorm.weight', 'llama_model.base_model.model.model.layers.27.post_attention_layernorm.weight', 'llama_model.base_model.model.model.norm.weight', 'llama_proj.0.weight', 'llama_proj.0.bias', 'llama_proj.2.weight', 'llama_proj.2.bias'], unexpected_keys=[])2025-11-29 11:01:23,598 [INFO] Start training
2025-11-29 11:01:23,605 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2025-11-29 11:01:23,606 [INFO] Loaded 33891 records for train split from the dataset.
2025-11-29 11:01:23,606 [INFO] Loaded 5200 records for valid split from the dataset.
2025-11-29 11:01:23,606 [INFO] Loaded 7331 records for test split from the dataset.
2025-11-29 11:01:23,610 [INFO] number of trainable parameters: 4591616
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\runners\runner_base.py:153: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
2025-11-29 11:01:23,612 [INFO] Start training epoch 0, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:01:51,222 [INFO] Averaged stats: lr: 0.000131  loss: 0.578815
2025-11-29 11:01:51,223 [INFO] Evaluating on valid.
2025-11-29 11:01:51,228 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:05:17,292 [INFO] Averaged stats: loss: 0.651443  acc: 0.649581 ***auc: 0.6964874109818093 ***uauc: 0.664721043856734 ***u-nDCG: 0.8605009059950074 ***AP@10: 3.0357034102775313 ***Coverage@10: 0.3071253071253071 ***Gini@10: 0.37002547770700644 ***DivRatio@10: 0.4899559039686428 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-29 11:05:17,298 [INFO] Saving checkpoint at epoch 0 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:05:17,750 [INFO] Start training
2025-11-29 11:05:17,755 [INFO] Start training epoch 1, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:05:45,195 [INFO] Averaged stats: lr: 0.000131  loss: 0.566350
2025-11-29 11:05:45,197 [INFO] Evaluating on valid.
2025-11-29 11:05:45,200 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:09:14,241 [INFO] Averaged stats: loss: 0.633438  acc: 0.650915 ***auc: 0.709990498489989 ***uauc: 0.6665198853348528 ***u-nDCG: 0.8606097436935226 ***AP@10: 3.028313456015852 ***Coverage@10: 0.30804668304668303 ***Gini@10: 0.3675348281466234 ***DivRatio@10: 0.49142577168054874 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-29 11:09:14,247 [INFO] Saving checkpoint at epoch 1 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:09:14,747 [INFO] Start training
2025-11-29 11:09:14,755 [INFO] Start training epoch 2, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:09:42,200 [INFO] Averaged stats: lr: 0.000131  loss: 0.524877
2025-11-29 11:09:42,202 [INFO] Evaluating on valid.
2025-11-29 11:09:42,205 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:13:22,417 [INFO] Averaged stats: loss: 0.623019  acc: 0.637767 ***auc: 0.7136302197612104 ***uauc: 0.6704451175107737 ***u-nDCG: 0.8626346743434409 ***AP@10: 3.040963765655207 ***Coverage@10: 0.30743243243243246 ***Gini@10: 0.36946052477654634 ***DivRatio@10: 0.49044585987261147 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 11:13:22,423 [INFO] Saving checkpoint at epoch 2 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:13:22,897 [INFO] Start training
2025-11-29 11:13:22,904 [INFO] Start training epoch 3, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:13:50,054 [INFO] Averaged stats: lr: 0.000131  loss: 0.522189
2025-11-29 11:13:50,056 [INFO] Evaluating on valid.
2025-11-29 11:13:50,061 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:17:18,251 [INFO] Averaged stats: loss: 0.615514  acc: 0.635480 ***auc: 0.7164943333196232 ***uauc: 0.6696978517201772 ***u-nDCG: 0.8610016479369983 ***AP@10: 3.036261072261935 ***Coverage@10: 0.30743243243243246 ***Gini@10: 0.36834062556747516 ***DivRatio@10: 0.49044585987261147 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-29 11:17:18,257 [INFO] Saving checkpoint at epoch 3 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:17:18,735 [INFO] Start training
2025-11-29 11:17:18,740 [INFO] Start training epoch 4, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:17:45,844 [INFO] Averaged stats: lr: 0.001000  loss: 0.582860
2025-11-29 11:17:45,845 [INFO] Evaluating on valid.
2025-11-29 11:17:45,849 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:21:35,592 [INFO] Averaged stats: loss: 0.633589  acc: 0.599848 ***auc: 0.7133617601565856 ***uauc: 0.6748012052379576 ***u-nDCG: 0.8636249021552251 ***AP@10: 3.028533509505905 ***Coverage@10: 0.31265356265356264 ***Gini@10: 0.36333358681412187 ***DivRatio@10: 0.49877511024007837 ***ORRatio@10: 0.018128368446839783 ***MGU@10: 0.0
2025-11-29 11:21:35,611 [INFO] Start training
2025-11-29 11:21:35,628 [INFO] Start training epoch 5, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:22:06,564 [INFO] Averaged stats: lr: 0.001000  loss: 0.518220
2025-11-29 11:22:06,567 [INFO] Evaluating on valid.
2025-11-29 11:22:06,581 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:26:09,629 [INFO] Averaged stats: loss: 0.619052  acc: 0.649771 ***auc: 0.7215344842153029 ***uauc: 0.6677285028203709 ***u-nDCG: 0.8600057460156443 ***AP@10: 3.0533446492764322 ***Coverage@10: 0.3012899262899263 ***Gini@10: 0.3732400169611647 ***DivRatio@10: 0.48064674179323863 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 11:26:09,635 [INFO] Saving checkpoint at epoch 5 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:26:10,119 [INFO] Start training
2025-11-29 11:26:10,125 [INFO] Start training epoch 6, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:26:37,688 [INFO] Averaged stats: lr: 0.001000  loss: 0.531259
2025-11-29 11:26:37,689 [INFO] Evaluating on valid.
2025-11-29 11:26:37,692 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:30:07,176 [INFO] Averaged stats: loss: 0.626639  acc: 0.655678 ***auc: 0.7157193195439928 ***uauc: 0.6656528494171303 ***u-nDCG: 0.8574923554343108 ***AP@10: 3.047283677463975 ***Coverage@10: 0.3058968058968059 ***Gini@10: 0.37001607606319453 ***DivRatio@10: 0.48799608035276826 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 11:30:07,182 [INFO] Start training
2025-11-29 11:30:07,188 [INFO] Start training epoch 7, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:30:34,185 [INFO] Averaged stats: lr: 0.001000  loss: 0.532198
2025-11-29 11:30:34,185 [INFO] Evaluating on valid.
2025-11-29 11:30:34,190 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:34:01,997 [INFO] Averaged stats: loss: 0.613924  acc: 0.654154 ***auc: 0.7224673367960861 ***uauc: 0.6707058545539094 ***u-nDCG: 0.8643901891685972 ***AP@10: 3.042359259208825 ***Coverage@10: 0.3055896805896806 ***Gini@10: 0.3679352174887176 ***DivRatio@10: 0.4875061244487996 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-29 11:34:02,002 [INFO] Saving checkpoint at epoch 7 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:34:02,472 [INFO] Start training
2025-11-29 11:34:02,479 [INFO] Start training epoch 8, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:34:29,831 [INFO] Averaged stats: lr: 0.001000  loss: 0.521374
2025-11-29 11:34:29,832 [INFO] Evaluating on valid.
2025-11-29 11:34:29,836 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:37:56,202 [INFO] Averaged stats: loss: 0.624047  acc: 0.637576 ***auc: 0.7241848546316484 ***uauc: 0.6863657536574159 ***u-nDCG: 0.8692512557229826 ***AP@10: 3.0469553075632057 ***Coverage@10: 0.3071253071253071 ***Gini@10: 0.3714434100930917 ***DivRatio@10: 0.4899559039686428 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-29 11:37:56,208 [INFO] Saving checkpoint at epoch 8 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:37:56,672 [INFO] Start training
2025-11-29 11:37:56,677 [INFO] Start training epoch 9, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:38:23,674 [INFO] Averaged stats: lr: 0.001000  loss: 0.512730
2025-11-29 11:38:23,675 [INFO] Evaluating on valid.
2025-11-29 11:38:23,680 [WARNING] item_category_dict not provided. MGU metric will be 0.

answer token ids: pos: 9454 neg ids: 2753
Prompt Pos Example 
#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user's preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> (<Popularity>) with the feature <TargetItemID>? Answer with "Yes" or "No". \n#Answer: Yes or No
llama_proj.0.weight
llama_proj.0.bias
llama_proj.2.weight
llama_proj.2.bias
prompt example: <s>#Question: A user has given high ratings to the following movies: "Best in Show (2000)", "High Fidelity (2000)", "Bring It On (2000)", "28 Days (2000)", "Perfect Storm, The (2000)", "Return to Me (2000)", "Thomas Crown Affair, The (1999)". Additionally, we have information about the user's preferences encoded in the feature <unk>. Using all available information, make a prediction about whether the user would enjoy the movie titled "My Dog Skip (1999)" (<Popularity>) with the feature <unk>? Answer with "Yes" or "No". \n#Answer:
#######prmpt decoded example:  <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <s ># Question :  A  user  has  given  high  ratings  to  the  following  movies :  " Dave  ( 1 9 9 3 )",  " Add ams  Family ,  The  ( 1 9 9 1 )",  " Ham let  ( 1 9 9 0 )",  " Cour age  Under  Fire  ( 1 9 9 6 )",  " P ump  Up  the  Volume  ( 1 9 9 0 )",  " B ul worth  ( 1 9 9 8 )",  " M ight y  Aph rod ite  ( 1 9 9 5 )",  " Four  Wed dings  and  a  Funeral  ( 1 9 9 4 )",  " In  the  Name  of  the  Father  ( 1 9 9 3 )",  " S cream  ( 1 9 9 6 )".  Additionally ,  we  have  information  about  the  user 's  preferences  encoded  in  the  feature   <unk> .  Using  all  available  information ,  make  a  prediction  about  whether  the  user  would  enjoy  the  movie  titled  " Last  Sup per ,  The  ( 1 9 9 5 )"  (< Pop ularity >)  with  the  feature   <unk> ?  Answer  with  " Yes "  or  " No ".  \ n # Answer :
Train: data epoch: [0]  [ 0/50]  eta: 0:00:40  lr: 0.000010  loss: 0.7526  time: 0.8145  data: 0.0000  max mem: 18851
Train: data epoch: [0]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.5771  time: 0.5478  data: 0.0000  max mem: 21510
Train: data epoch: [0] Total time: 0:00:27 (0.5522 s / it)
Evaluation  [ 0/82]  eta: 0:02:22  loss: 0.6336  acc: 0.6562  time: 1.7378  data: 0.0154  max mem: 25139
Evaluation  [16/82]  eta: 0:02:39  loss: 0.7420  acc: 0.5625  time: 2.4198  data: 0.0075  max mem: 29968
Evaluation  [32/82]  eta: 0:02:04  loss: 0.7270  acc: 0.5938  time: 2.5659  data: 0.0070  max mem: 31013
Evaluation  [48/82]  eta: 0:01:26  loss: 0.7373  acc: 0.6406  time: 2.6033  data: 0.0070  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6852  acc: 0.6094  time: 2.5782  data: 0.0073  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6603  acc: 0.5938  time: 2.4902  data: 0.0068  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4890  acc: 0.7500  time: 2.3899  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:25 (2.5113 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07638859748840332 uauc: 0.664721043856734
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002523183822631836 u-nDCG: 0.8605009059950074
Metrics @10: AP=3.0357, Cov=0.3071, Gini=0.3700
Advanced @10: DivRatio=0.4900, ORRatio=0.0206, MGU=0.0000
rank_0 auc: 0.6964874109818093
Train: data epoch: [1]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.7579  time: 0.5095  data: 0.0000  max mem: 32101
Train: data epoch: [1]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.3678  time: 0.5407  data: 0.0000  max mem: 32101
Train: data epoch: [1] Total time: 0:00:27 (0.5488 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6056  acc: 0.6406  time: 1.5701  data: 0.0132  max mem: 32101
Evaluation  [16/82]  eta: 0:02:44  loss: 0.7287  acc: 0.5625  time: 2.4855  data: 0.0072  max mem: 32101
Evaluation  [32/82]  eta: 0:02:07  loss: 0.6983  acc: 0.5938  time: 2.5973  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:27  loss: 0.7197  acc: 0.6719  time: 2.5753  data: 0.0070  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6853  acc: 0.6250  time: 2.6236  data: 0.0073  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6553  acc: 0.5781  time: 2.5372  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4694  acc: 0.6875  time: 2.4351  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:28 (2.5476 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07392430305480957 uauc: 0.6665198853348528
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.001523733139038086 u-nDCG: 0.8606097436935226
Metrics @10: AP=3.0283, Cov=0.3080, Gini=0.3675
Advanced @10: DivRatio=0.4914, ORRatio=0.0206, MGU=0.0000
rank_0 auc: 0.709990498489989
Train: data epoch: [2]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.7023  time: 0.5194  data: 0.0000  max mem: 32101
Train: data epoch: [2]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.4158  time: 0.5430  data: 0.0000  max mem: 32101
Train: data epoch: [2] Total time: 0:00:27 (0.5489 s / it)
Evaluation  [ 0/82]  eta: 0:02:11  loss: 0.6239  acc: 0.6562  time: 1.6015  data: 0.0144  max mem: 32101
Evaluation  [16/82]  eta: 0:02:47  loss: 0.6897  acc: 0.5938  time: 2.5356  data: 0.0076  max mem: 32101
Evaluation  [32/82]  eta: 0:02:08  loss: 0.6461  acc: 0.7031  time: 2.5783  data: 0.0072  max mem: 32101
Evaluation  [48/82]  eta: 0:01:27  loss: 0.6604  acc: 0.5938  time: 2.5939  data: 0.0071  max mem: 32101
Evaluation  [64/82]  eta: 0:00:49  loss: 0.6653  acc: 0.5938  time: 3.1415  data: 0.0071  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6367  acc: 0.6094  time: 2.5515  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4831  acc: 0.7500  time: 2.4412  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:40 (2.6838 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07432317733764648 uauc: 0.6704451175107737
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030400753021240234 u-nDCG: 0.8626346743434409
Metrics @10: AP=3.0410, Cov=0.3074, Gini=0.3695
Advanced @10: DivRatio=0.4904, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7136302197612104
Train: data epoch: [3]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.6434  time: 0.5176  data: 0.0000  max mem: 32101
Train: data epoch: [3]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.6122  time: 0.5485  data: 0.0000  max mem: 32101
Train: data epoch: [3] Total time: 0:00:27 (0.5430 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6034  acc: 0.6250  time: 1.5646  data: 0.0146  max mem: 32101
Evaluation  [16/82]  eta: 0:02:46  loss: 0.6727  acc: 0.5938  time: 2.5168  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:06  loss: 0.6309  acc: 0.6719  time: 2.5411  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:26  loss: 0.6742  acc: 0.5938  time: 2.5558  data: 0.0070  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6363  acc: 0.6094  time: 2.6184  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6185  acc: 0.6250  time: 2.5140  data: 0.0069  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5004  acc: 0.8125  time: 2.4136  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:28 (2.5372 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07526707649230957 uauc: 0.6696978517201772
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost:2025-11-29 11:41:49,722 [INFO] Averaged stats: loss: 0.614204  acc: 0.650724 ***auc: 0.7211075918683467 ***uauc: 0.6612965947133653 ***u-nDCG: 0.8551880423287472 ***AP@10: 3.0232244748216655 ***Coverage@10: 0.3098894348894349 ***Gini@10: 0.3660961197337631 ***DivRatio@10: 0.4943655071043606 ***ORRatio@10: 0.021558059774620286 ***MGU@10: 0.0
2025-11-29 11:41:49,730 [INFO] Start training
2025-11-29 11:41:49,737 [INFO] Start training epoch 10, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:42:16,632 [INFO] Averaged stats: lr: 0.001000  loss: 0.496503
2025-11-29 11:42:16,634 [INFO] Evaluating on valid.
2025-11-29 11:42:16,638 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:45:41,661 [INFO] Averaged stats: loss: 0.623804  acc: 0.648247 ***auc: 0.7220432656507273 ***uauc: 0.6726897700904677 ***u-nDCG: 0.8623501984042606 ***AP@10: 3.02189086914283 ***Coverage@10: 0.31296068796068793 ***Gini@10: 0.365923975576251 ***DivRatio@10: 0.49926506614404703 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 11:45:41,668 [INFO] Start training
2025-11-29 11:45:41,674 [INFO] Start training epoch 11, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:46:08,822 [INFO] Averaged stats: lr: 0.001000  loss: 0.496292
2025-11-29 11:46:08,823 [INFO] Evaluating on valid.
2025-11-29 11:46:08,826 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:49:36,345 [INFO] Averaged stats: loss: 0.621544  acc: 0.647866 ***auc: 0.7267355920863217 ***uauc: 0.6692996125225608 ***u-nDCG: 0.8614794659887159 ***AP@10: 3.053210661627799 ***Coverage@10: 0.30743243243243246 ***Gini@10: 0.372475638031738 ***DivRatio@10: 0.49044585987261147 ***ORRatio@10: 0.020088192062714356 ***MGU@10: 0.0
2025-11-29 11:49:36,351 [INFO] Saving checkpoint at epoch 11 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 11:49:36,813 [INFO] Start training
2025-11-29 11:49:36,820 [INFO] Start training epoch 12, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:50:03,948 [INFO] Averaged stats: lr: 0.001000  loss: 0.468839
2025-11-29 11:50:03,949 [INFO] Evaluating on valid.
2025-11-29 11:50:03,953 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:53:29,934 [INFO] Averaged stats: loss: 0.668371  acc: 0.624619 ***auc: 0.7094872852156118 ***uauc: 0.6854682748565666 ***u-nDCG: 0.8703688512707983 ***AP@10: 3.072598217143784 ***Coverage@10: 0.3025184275184275 ***Gini@10: 0.3769760518507649 ***DivRatio@10: 0.4826065654091132 ***ORRatio@10: 0.020088192062714356 ***MGU@10: 0.0
2025-11-29 11:53:29,939 [INFO] Start training
2025-11-29 11:53:29,946 [INFO] Start training epoch 13, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:53:56,859 [INFO] Averaged stats: lr: 0.001000  loss: 0.553460
2025-11-29 11:53:56,861 [INFO] Evaluating on valid.
2025-11-29 11:53:56,865 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 11:57:20,604 [INFO] Averaged stats: loss: 0.625053  acc: 0.666921 ***auc: 0.726576045711781 ***uauc: 0.6779824904791495 ***u-nDCG: 0.8672343171164619 ***AP@10: 3.0232802316416625 ***Coverage@10: 0.3083538083538084 ***Gini@10: 0.3681198771791814 ***DivRatio@10: 0.4919157275845174 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-29 11:57:20,610 [INFO] Start training
2025-11-29 11:57:20,616 [INFO] Start training epoch 14, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 11:57:47,798 [INFO] Averaged stats: lr: 0.000999  loss: 0.520354
2025-11-29 11:57:47,798 [INFO] Evaluating on valid.
2025-11-29 11:57:47,802 [WARNING] item_category_dict not provided. MGU metric will be 0.
 0.003546476364135742 u-nDCG: 0.8610016479369983
Metrics @10: AP=3.0363, Cov=0.3074, Gini=0.3683
Advanced @10: DivRatio=0.4904, ORRatio=0.0191, MGU=0.0000
rank_0 auc: 0.7164943333196232
Train: data epoch: [4]  [ 0/50]  eta: 0:00:25  lr: 0.001000  loss: 0.6812  time: 0.5110  data: 0.0000  max mem: 32101
Train: data epoch: [4]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.8651  time: 0.5497  data: 0.0000  max mem: 32101
Train: data epoch: [4] Total time: 0:00:27 (0.5421 s / it)
Evaluation  [ 0/82]  eta: 0:02:10  loss: 0.6067  acc: 0.6719  time: 1.5950  data: 0.0150  max mem: 32101
Evaluation  [16/82]  eta: 0:02:51  loss: 0.6637  acc: 0.6719  time: 2.5973  data: 0.0160  max mem: 32101
Evaluation  [32/82]  eta: 0:02:16  loss: 0.6326  acc: 0.6406  time: 2.8709  data: 0.0207  max mem: 32101
Evaluation  [48/82]  eta: 0:01:34  loss: 0.6609  acc: 0.5469  time: 2.8091  data: 0.0169  max mem: 32101
Evaluation  [64/82]  eta: 0:00:51  loss: 0.6572  acc: 0.5938  time: 3.0034  data: 0.0188  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6390  acc: 0.5781  time: 2.8046  data: 0.0230  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5078  acc: 0.6875  time: 2.6936  data: 0.0221  max mem: 32101
Evaluation Total time: 0:03:49 (2.7976 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19518828392028809 uauc: 0.6748012052379576
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.008686542510986328 u-nDCG: 0.8636249021552251
Metrics @10: AP=3.0285, Cov=0.3127, Gini=0.3633
Advanced @10: DivRatio=0.4988, ORRatio=0.0181, MGU=0.0000
rank_0 auc: 0.7133617601565856
Train: data epoch: [5]  [ 0/50]  eta: 0:00:28  lr: 0.001000  loss: 0.7794  time: 0.5644  data: 0.0000  max mem: 32101
Train: data epoch: [5]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.5608  time: 0.6292  data: 0.0000  max mem: 32101
Train: data epoch: [5] Total time: 0:00:30 (0.6187 s / it)
Evaluation  [ 0/82]  eta: 0:02:35  loss: 0.5853  acc: 0.6875  time: 1.8919  data: 0.0680  max mem: 32101
Evaluation  [16/82]  eta: 0:03:17  loss: 0.6705  acc: 0.6094  time: 2.9922  data: 0.0288  max mem: 32101
Evaluation  [32/82]  eta: 0:02:27  loss: 0.6685  acc: 0.6719  time: 2.9017  data: 0.0298  max mem: 32101
Evaluation  [48/82]  eta: 0:01:40  loss: 0.6653  acc: 0.6719  time: 2.9333  data: 0.0216  max mem: 32101
Evaluation  [64/82]  eta: 0:00:54  loss: 0.6386  acc: 0.7188  time: 3.2316  data: 0.0234  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6435  acc: 0.6250  time: 2.8556  data: 0.0195  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4679  acc: 0.7500  time: 2.7336  data: 0.0181  max mem: 32101
Evaluation Total time: 0:04:02 (2.9622 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07854628562927246 uauc: 0.6677285028203709
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030198097229003906 u-nDCG: 0.8600057460156443
Metrics @10: AP=3.0533, Cov=0.3013, Gini=0.3732
Advanced @10: DivRatio=0.4806, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7215344842153029
Train: data epoch: [6]  [ 0/50]  eta: 0:00:27  lr: 0.001000  loss: 0.5389  time: 0.5421  data: 0.0000  max mem: 32101
Train: data epoch: [6]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.3900  time: 0.5528  data: 0.0000  max mem: 32101
Train: data epoch: [6] Total time: 0:00:27 (0.5512 s / it)
Evaluation  [ 0/82]  eta: 0:02:31  loss: 0.5869  acc: 0.6875  time: 1.8476  data: 0.0138  max mem: 32101
Evaluation  [16/82]  eta: 0:02:43  loss: 0.7144  acc: 0.5938  time: 2.4710  data: 0.0076  max mem: 32101
Evaluation  [32/82]  eta: 0:02:06  loss: 0.7000  acc: 0.5781  time: 2.5878  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:27  loss: 0.6713  acc: 0.6875  time: 2.6190  data: 0.0071  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6787  acc: 0.7031  time: 2.6604  data: 0.0071  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6457  acc: 0.6406  time: 2.5584  data: 0.0069  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4543  acc: 0.7500  time: 2.4528  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:29 (2.5530 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07486224174499512 uauc: 0.6656528494171303
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004564762115478516 u-nDCG: 0.8574923554343108
Metrics @10: AP=3.0473, Cov=0.3059, Gini=0.3700
Advanced @10: DivRatio=0.4880, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7157193195439928
Train: data epoch: [7]  [ 0/50]  eta: 0:00:26  lr: 0.001000  loss: 0.7790  time: 0.5259  data: 0.0000  max mem: 32101
Train: data epoch: [7]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.5369  time: 0.5404  data: 0.0000  max mem: 32101
Train: data epoch: [7] Total time: 0:00:26 (0.5399 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.6091  acc: 0.6875  time: 1.5738  data: 0.0136  max mem: 32101
Evaluation  [16/82]  eta: 0:02:45  loss: 0.6858  acc: 0.6406  time: 2.5138  data: 0.0073  max mem: 32101
Evaluation  [32/82]  eta: 0:02:06  loss: 0.6656  acc: 0.6406  time: 2.5548  data: 0.0070  max mem: 32101
Evaluation  [48/82]  eta: 0:01:26  loss: 0.6740  acc: 0.6094  time: 2.5437  data: 0.0070  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6294  acc: 0.7188  time: 2.6214  data: 0.0071  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6252  acc: 0.6719  time: 2.5097  data: 0.0067  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4827  acc: 0.6875  time: 2.4077  data: 0.0064  max mem: 32101
Evaluation Total time: 0:03:27 (2.5325 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0791482925415039 uauc: 0.6707058545539094
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003015279769897461 u-nDCG: 0.8643901891685972
Metrics @10: AP=3.0424, Cov=0.3056, Gini=0.3679
Advanced @10: DivRatio=0.4875, ORRatio=0.0206, MGU=0.0000
rank_0 auc: 0.7224673367960861
Train: data epoch: [8]  [ 0/50]  eta: 0:00:25  lr: 0.001000  loss: 0.4153  time: 0.5052  data: 0.0000  max mem: 32101
Train: data epoch: [8]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.6241  time: 0.5474  data: 0.0000  max mem: 32101
Train: data epoch: [8] Total time: 0:00:27 (0.5470 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6420  acc: 0.6250  time: 1.5668  data: 0.0134  max mem: 32101
Evaluation  [16/82]  eta: 0:02:41  loss: 0.6935  acc: 0.5938  time: 2.4430  data: 0.0077  max mem: 32101
Evaluation  [32/82]  eta: 0:02:05  loss: 0.6364  acc: 0.6719  time: 2.5659  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:26  loss: 0.6246  acc: 0.6406  time: 2.5747  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6457  acc: 0.6719  time: 2.5863  data: 0.0069  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6827  acc: 0.6562  time: 2.4904  data: 0.0065  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5516  acc: 0.7500  time: 2.3869  data: 0.0062  max mem: 32101
Evaluation Total time: 0:03:26 (2.5150 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07526278495788574 uauc: 0.6863657536574159
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030794143676757812 u-nDCG: 0.8692512557229826
Metrics @10: AP=3.0470, Cov=0.3071, Gini=0.3714
Advanced @10: DivRatio=0.4900, ORRatio=0.0206, MGU=0.0000
rank_0 auc: 0.7241848546316484
Train: data epoch: [9]  [ 0/50]  eta: 0:00:27  lr: 0.001000  loss: 0.5428  time: 0.5528  data: 0.0000  max mem: 32101
Train: data epoch: [9]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.6772  time: 0.5355  data: 0.0000  max mem: 32101
Train: data epoch: [9] Total time: 0:00:26 (0.5399 s / it)
2025-11-29 12:01:11,093 [INFO] Averaged stats: loss: 0.609433  acc: 0.652439 ***auc: 0.7290146032818889 ***uauc: 0.6719630982273886 ***u-nDCG: 0.8634560828847317 ***AP@10: 3.0353191196949787 ***Coverage@10: 0.3092751842751843 ***Gini@10: 0.3679831575833449 ***DivRatio@10: 0.49338559529642334 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 12:01:11,100 [INFO] Saving checkpoint at epoch 14 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251129110\checkpoint_best.pth.
2025-11-29 12:01:11,571 [INFO] Start training
2025-11-29 12:01:11,578 [INFO] Start training epoch 15, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:01:38,926 [INFO] Averaged stats: lr: 0.000999  loss: 0.486543
2025-11-29 12:01:38,927 [INFO] Evaluating on valid.
2025-11-29 12:01:38,931 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:05:02,721 [INFO] Averaged stats: loss: 0.622394  acc: 0.611280 ***auc: 0.7233722743294858 ***uauc: 0.663236973639993 ***u-nDCG: 0.8607333592181313 ***AP@10: 3.0271207925455395 ***Coverage@10: 0.3101965601965602 ***Gini@10: 0.3649909527944465 ***DivRatio@10: 0.4948554630083293 ***ORRatio@10: 0.0171484566389025 ***MGU@10: 0.0
2025-11-29 12:05:02,727 [INFO] Start training
2025-11-29 12:05:02,734 [INFO] Start training epoch 16, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:05:29,900 [INFO] Averaged stats: lr: 0.000999  loss: 0.491468
2025-11-29 12:05:29,901 [INFO] Evaluating on valid.
2025-11-29 12:05:29,905 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:08:54,402 [INFO] Averaged stats: loss: 0.622502  acc: 0.633765 ***auc: 0.7189879043208781 ***uauc: 0.6620862269326161 ***u-nDCG: 0.8543165078558669 ***AP@10: 2.997333023235766 ***Coverage@10: 0.31357493857493857 ***Gini@10: 0.36093818157737 ***DivRatio@10: 0.5002449779519843 ***ORRatio@10: 0.018128368446839783 ***MGU@10: 0.0
2025-11-29 12:08:54,409 [INFO] Start training
2025-11-29 12:08:54,415 [INFO] Start training epoch 17, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:09:21,528 [INFO] Averaged stats: lr: 0.000999  loss: 0.502607
2025-11-29 12:09:21,530 [INFO] Evaluating on valid.
2025-11-29 12:09:21,534 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:12:45,000 [INFO] Averaged stats: loss: 0.626775  acc: 0.623666 ***auc: 0.7202780843566005 ***uauc: 0.6675910125702297 ***u-nDCG: 0.8570241476416912 ***AP@10: 3.031352358860685 ***Coverage@10: 0.31111793611793614 ***Gini@10: 0.3671578639857259 ***DivRatio@10: 0.49632533072023516 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-29 12:12:45,007 [INFO] Start training
2025-11-29 12:12:45,015 [INFO] Start training epoch 18, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:13:12,164 [INFO] Averaged stats: lr: 0.000999  loss: 0.463148
2025-11-29 12:13:12,165 [INFO] Evaluating on valid.
2025-11-29 12:13:12,170 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:16:36,476 [INFO] Averaged stats: loss: 0.643795  acc: 0.648247 ***auc: 0.7093535751083304 ***uauc: 0.6351701193078974 ***u-nDCG: 0.8473905389961551 ***AP@10: 2.9696298908241263 ***Coverage@10: 0.31971744471744473 ***Gini@10: 0.35784713093400844 ***DivRatio@10: 0.5100440960313571 ***ORRatio@10: 0.018128368446839783 ***MGU@10: 0.0
2025-11-29 12:16:36,483 [INFO] Start training
2025-11-29 12:16:36,489 [INFO] Start training epoch 19, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:17:03,424 [INFO] Averaged stats: lr: 0.000999  loss: 0.450473
2025-11-29 12:17:03,425 [INFO] Evaluating on valid.
2025-11-29 12:17:03,429 [WARNING] item_category_dict not provided. MGU metric will be 0.
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.6176  acc: 0.6250  time: 1.5772  data: 0.0148  max mem: 32101
Evaluation  [16/82]  eta: 0:02:41  loss: 0.6849  acc: 0.5625  time: 2.4455  data: 0.0073  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6539  acc: 0.6406  time: 2.5407  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6523  acc: 0.6562  time: 2.5446  data: 0.0069  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6322  acc: 0.7031  time: 2.6275  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6499  acc: 0.6406  time: 2.4910  data: 0.0068  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4737  acc: 0.7500  time: 2.3808  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:25 (2.5111 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07297873497009277 uauc: 0.6612965947133653
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031430721282958984 u-nDCG: 0.8551880423287472
Metrics @10: AP=3.0232, Cov=0.3099, Gini=0.3661
Advanced @10: DivRatio=0.4944, ORRatio=0.0216, MGU=0.0000
rank_0 auc: 0.7211075918683467
Train: data epoch: [10]  [ 0/50]  eta: 0:00:26  lr: 0.001000  loss: 0.4998  time: 0.5222  data: 0.0000  max mem: 32101
Train: data epoch: [10]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.5653  time: 0.5413  data: 0.0000  max mem: 32101
Train: data epoch: [10] Total time: 0:00:26 (0.5379 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6135  acc: 0.6406  time: 1.5662  data: 0.0144  max mem: 32101
Evaluation  [16/82]  eta: 0:02:39  loss: 0.7048  acc: 0.6094  time: 2.4093  data: 0.0076  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.5972  acc: 0.7031  time: 2.5874  data: 0.0070  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6347  acc: 0.6562  time: 2.5151  data: 0.0071  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6357  acc: 0.7188  time: 2.5669  data: 0.0070  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6640  acc: 0.6719  time: 2.5468  data: 0.0072  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4429  acc: 0.7500  time: 2.4477  data: 0.0069  max mem: 32101
Evaluation Total time: 0:03:24 (2.4986 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07435798645019531 uauc: 0.6726897700904677
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0025300979614257812 u-nDCG: 0.8623501984042606
Metrics @10: AP=3.0219, Cov=0.3130, Gini=0.3659
Advanced @10: DivRatio=0.4993, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7220432656507273
Train: data epoch: [11]  [ 0/50]  eta: 0:00:26  lr: 0.001000  loss: 0.4221  time: 0.5289  data: 0.0000  max mem: 32101
Train: data epoch: [11]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.5243  time: 0.5468  data: 0.0000  max mem: 32101
Train: data epoch: [11] Total time: 0:00:27 (0.5429 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6220  acc: 0.6562  time: 1.5533  data: 0.0139  max mem: 32101
Evaluation  [16/82]  eta: 0:02:37  loss: 0.6801  acc: 0.6094  time: 2.3865  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:06  loss: 0.6362  acc: 0.6875  time: 2.6336  data: 0.0069  max mem: 32101
Evaluation  [48/82]  eta: 0:01:27  loss: 0.6583  acc: 0.5781  time: 2.5990  data: 0.0068  max mem: 32101
Evaluation  [64/82]  eta: 0:00:46  loss: 0.6661  acc: 0.6406  time: 2.5570  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6311  acc: 0.6875  time: 2.5377  data: 0.0067  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4207  acc: 0.7500  time: 2.4370  data: 0.0063  max mem: 32101
Evaluation Total time: 0:03:27 (2.5290 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07632112503051758 uauc: 0.6692996125225608
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030717849731445312 u-nDCG: 0.8614794659887159
Metrics @10: AP=3.0532, Cov=0.3074, Gini=0.3725
Advanced @10: DivRatio=0.4904, ORRatio=0.0201, MGU=0.0000
rank_0 auc: 0.7267355920863217
Train: data epoch: [12]  [ 0/50]  eta: 0:00:26  lr: 0.001000  loss: 0.5057  time: 0.5351  data: 0.0000  max mem: 32101
Train: data epoch: [12]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.4901  time: 0.5437  data: 0.0000  max mem: 32101
Train: data epoch: [12] Total time: 0:00:27 (0.5425 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6597  acc: 0.5781  time: 1.5625  data: 0.0131  max mem: 32101
Evaluation  [16/82]  eta: 0:02:36  loss: 0.7235  acc: 0.6719  time: 2.3727  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6491  acc: 0.6875  time: 2.5953  data: 0.0072  max mem: 32101
Evaluation  [48/82]  eta: 0:01:26  loss: 0.6869  acc: 0.6094  time: 2.5736  data: 0.0070  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7076  acc: 0.6250  time: 2.5291  data: 0.0069  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6856  acc: 0.6406  time: 2.5428  data: 0.0066  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4553  acc: 0.8125  time: 2.4429  data: 0.0062  max mem: 32101
Evaluation Total time: 0:03:25 (2.5103 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07498788833618164 uauc: 0.6854682748565666
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030477046966552734 u-nDCG: 0.8703688512707983
Metrics @10: AP=3.0726, Cov=0.3025, Gini=0.3770
Advanced @10: DivRatio=0.4826, ORRatio=0.0201, MGU=0.0000
rank_0 auc: 0.7094872852156118
Train: data epoch: [13]  [ 0/50]  eta: 0:00:25  lr: 0.001000  loss: 0.5374  time: 0.5191  data: 0.0000  max mem: 32101
Train: data epoch: [13]  [49/50]  eta: 0:00:00  lr: 0.001000  loss: 0.5625  time: 0.5388  data: 0.0000  max mem: 32101
Train: data epoch: [13] Total time: 0:00:26 (0.5383 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6034  acc: 0.6406  time: 1.5590  data: 0.0131  max mem: 32101
Evaluation  [16/82]  eta: 0:02:35  loss: 0.7078  acc: 0.6250  time: 2.3608  data: 0.0074  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6707  acc: 0.6406  time: 2.5502  data: 0.0072  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6646  acc: 0.7188  time: 2.5700  data: 0.0073  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6668  acc: 0.6562  time: 2.5101  data: 0.0070  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6712  acc: 0.6406  time: 2.5193  data: 0.0072  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4821  acc: 0.7500  time: 2.4181  data: 0.0068  max mem: 32101
Evaluation Total time: 0:03:23 (2.4829 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07938551902770996 uauc: 0.6779824904791495
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030431747436523438 u-nDCG: 0.8672343171164619
Metrics @10: AP=3.0233, Cov=0.3084, Gini=0.3681
Advanced @10: DivRatio=0.4919, ORRatio=0.0191, MGU=0.0000
rank_0 auc: 0.726576045711781
Train: data epoch: [14]  [ 0/50]  eta: 0:00:26  lr: 0.001000  loss: 0.4524  time: 0.5384  data: 0.0000  max mem: 32101
Train: data epoch: [14]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.6147  time: 0.5387  data: 0.0000  max mem: 32101
Train: data epoch: [14] Total time: 0:00:27 (0.5436 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.5932  acc: 0.6406  time: 1.5717  data: 0.0133  max mem: 32101
Evaluation  [16/82]  eta: 0:02:37  loss: 0.6839  acc: 0.6094  time: 2.3830  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6297  acc: 0.6719  time: 2.5416  data: 0.0070  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6254  acc: 0.6562  time: 2.5685  data: 0.0071  max mem: 32101
2025-11-29 12:20:27,874 [INFO] Averaged stats: loss: 0.627202  acc: 0.643293 ***auc: 0.7165584785348875 ***uauc: 0.6628916968089883 ***u-nDCG: 0.8541911472817091 ***AP@10: 2.9974751262961625 ***Coverage@10: 0.3178746928746929 ***Gini@10: 0.3548563624442883 ***DivRatio@10: 0.5071043606075453 ***ORRatio@10: 0.017638412542871143 ***MGU@10: 0.0
2025-11-29 12:20:27,881 [INFO] Start training
2025-11-29 12:20:27,886 [INFO] Start training epoch 20, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:20:55,117 [INFO] Averaged stats: lr: 0.000999  loss: 0.517485
2025-11-29 12:20:55,118 [INFO] Evaluating on valid.
2025-11-29 12:20:55,122 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:24:18,776 [INFO] Averaged stats: loss: 0.666067  acc: 0.584032 ***auc: 0.7038425062723477 ***uauc: 0.6418284083281226 ***u-nDCG: 0.8481347417356767 ***AP@10: 3.021713076817867 ***Coverage@10: 0.31265356265356264 ***Gini@10: 0.3632007500464447 ***DivRatio@10: 0.49877511024007837 ***ORRatio@10: 0.021068103870651642 ***MGU@10: 0.0
2025-11-29 12:24:18,783 [INFO] Start training
2025-11-29 12:24:18,789 [INFO] Start training epoch 21, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:24:46,029 [INFO] Averaged stats: lr: 0.000999  loss: 0.466719
2025-11-29 12:24:46,032 [INFO] Evaluating on valid.
2025-11-29 12:24:46,035 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:28:11,013 [INFO] Averaged stats: loss: 0.647856  acc: 0.608232 ***auc: 0.7104083332949749 ***uauc: 0.6736427101464683 ***u-nDCG: 0.855808493845456 ***AP@10: 2.99759169231918 ***Coverage@10: 0.3157248157248157 ***Gini@10: 0.36224136714855193 ***DivRatio@10: 0.5036746692797648 ***ORRatio@10: 0.018128368446839783 ***MGU@10: 0.0
2025-11-29 12:28:11,020 [INFO] Start training
2025-11-29 12:28:11,026 [INFO] Start training epoch 22, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:28:38,363 [INFO] Averaged stats: lr: 0.000999  loss: 0.479102
2025-11-29 12:28:38,365 [INFO] Evaluating on valid.
2025-11-29 12:28:38,370 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:32:01,848 [INFO] Averaged stats: loss: 0.625205  acc: 0.615663 ***auc: 0.7148975332155655 ***uauc: 0.6487242382844411 ***u-nDCG: 0.8451466824124894 ***AP@10: 2.9696985206765816 ***Coverage@10: 0.324017199017199 ***Gini@10: 0.35187054018218933 ***DivRatio@10: 0.5169034786869182 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-29 12:32:01,855 [INFO] Start training
2025-11-29 12:32:01,861 [INFO] Start training epoch 23, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:32:29,036 [INFO] Averaged stats: lr: 0.000999  loss: 0.429812
2025-11-29 12:32:29,037 [INFO] Evaluating on valid.
2025-11-29 12:32:29,042 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:35:52,652 [INFO] Averaged stats: loss: 0.653172  acc: 0.628811 ***auc: 0.7194931963753797 ***uauc: 0.6712633664789895 ***u-nDCG: 0.8590396853657598 ***AP@10: 3.0156630079061055 ***Coverage@10: 0.31203931203931207 ***Gini@10: 0.3637276385282805 ***DivRatio@10: 0.4977951984321411 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 12:35:52,659 [INFO] Start training
2025-11-29 12:35:52,665 [INFO] Start training epoch 24, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:36:19,771 [INFO] Averaged stats: lr: 0.000999  loss: 0.456523
2025-11-29 12:36:19,773 [INFO] Evaluating on valid.
2025-11-29 12:36:19,777 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:39:44,976 [INFO] Averaged stats: loss: 0.633440  acc: 0.612043 ***auc: 0.7128497863088274 ***uauc: 0.6664999854451639 ***u-nDCG: 0.8628745282036524 ***AP@10: 3.0135403335561235 ***Coverage@10: 0.3132678132678133 ***Gini@10: 0.36439557694709435 ***DivRatio@10: 0.4997550220480157 ***ORRatio@10: 0.020088192062714356 ***MGU@10: 0.0
2025-11-29 12:39:44,983 [INFO] Start training
2025-11-29 12:39:44,988 [INFO] Start training epoch 25, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6612  acc: 0.6562  time: 2.5160  data: 0.0074  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6358  acc: 0.5938  time: 2.4619  data: 0.0069  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4798  acc: 0.7500  time: 2.3591  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:23 (2.4775 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07513761520385742 uauc: 0.6719630982273886
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030112266540527344 u-nDCG: 0.8634560828847317
Metrics @10: AP=3.0353, Cov=0.3093, Gini=0.3680
Advanced @10: DivRatio=0.4934, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7290146032818889
Train: data epoch: [15]  [ 0/50]  eta: 0:00:25  lr: 0.000999  loss: 0.4497  time: 0.5052  data: 0.0000  max mem: 32101
Train: data epoch: [15]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.3957  time: 0.5453  data: 0.0000  max mem: 32101
Train: data epoch: [15] Total time: 0:00:27 (0.5470 s / it)
Evaluation  [ 0/82]  eta: 0:02:20  loss: 0.6183  acc: 0.6250  time: 1.7181  data: 0.0140  max mem: 32101
Evaluation  [16/82]  eta: 0:02:37  loss: 0.6731  acc: 0.6562  time: 2.3909  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6182  acc: 0.6250  time: 2.5248  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:24  loss: 0.6122  acc: 0.6250  time: 2.5227  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6670  acc: 0.5938  time: 2.5715  data: 0.0073  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6634  acc: 0.6406  time: 2.4679  data: 0.0069  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4714  acc: 0.7500  time: 2.3719  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:23 (2.4835 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08060860633850098 uauc: 0.663236973639993
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031006336212158203 u-nDCG: 0.8607333592181313
Metrics @10: AP=3.0271, Cov=0.3102, Gini=0.3650
Advanced @10: DivRatio=0.4949, ORRatio=0.0171, MGU=0.0000
rank_0 auc: 0.7233722743294858
Train: data epoch: [16]  [ 0/50]  eta: 0:00:27  lr: 0.000999  loss: 0.7977  time: 0.5417  data: 0.0005  max mem: 32101
Train: data epoch: [16]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.3569  time: 0.5390  data: 0.0000  max mem: 32101
Train: data epoch: [16] Total time: 0:00:27 (0.5433 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6080  acc: 0.6406  time: 1.5591  data: 0.0132  max mem: 32101
Evaluation  [16/82]  eta: 0:02:39  loss: 0.6444  acc: 0.6094  time: 2.4239  data: 0.0079  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.5871  acc: 0.7344  time: 2.5422  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6429  acc: 0.6562  time: 2.5364  data: 0.0073  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6703  acc: 0.5938  time: 2.5653  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6645  acc: 0.5938  time: 2.4584  data: 0.0071  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4845  acc: 0.6875  time: 2.3593  data: 0.0067  max mem: 32101
Evaluation Total time: 0:03:24 (2.4922 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0741262435913086 uauc: 0.6620862269326161
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030434131622314453 u-nDCG: 0.8543165078558669
Metrics @10: AP=2.9973, Cov=0.3136, Gini=0.3609
Advanced @10: DivRatio=0.5002, ORRatio=0.0181, MGU=0.0000
rank_0 auc: 0.7189879043208781
Train: data epoch: [17]  [ 0/50]  eta: 0:00:25  lr: 0.000999  loss: 0.5636  time: 0.5160  data: 0.0000  max mem: 32101
Train: data epoch: [17]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.4919  time: 0.5391  data: 0.0000  max mem: 32101
Train: data epoch: [17] Total time: 0:00:27 (0.5423 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6077  acc: 0.6719  time: 1.5569  data: 0.0132  max mem: 32101
Evaluation  [16/82]  eta: 0:02:39  loss: 0.6544  acc: 0.6562  time: 2.4196  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.5899  acc: 0.7031  time: 2.5210  data: 0.0073  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6562  acc: 0.6094  time: 2.5227  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6571  acc: 0.6250  time: 2.5571  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6197  acc: 0.6719  time: 2.4839  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4124  acc: 0.7500  time: 2.3850  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:23 (2.4796 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07587337493896484 uauc: 0.6675910125702297
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0025267601013183594 u-nDCG: 0.8570241476416912
Metrics @10: AP=3.0314, Cov=0.3111, Gini=0.3672
Advanced @10: DivRatio=0.4963, ORRatio=0.0191, MGU=0.0000
rank_0 auc: 0.7202780843566005
Train: data epoch: [18]  [ 0/50]  eta: 0:00:26  lr: 0.000999  loss: 0.3726  time: 0.5284  data: 0.0000  max mem: 32101
Train: data epoch: [18]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.8620  time: 0.5411  data: 0.0000  max mem: 32101
Train: data epoch: [18] Total time: 0:00:27 (0.5430 s / it)
Evaluation  [ 0/82]  eta: 0:02:06  loss: 0.6375  acc: 0.6719  time: 1.5476  data: 0.0138  max mem: 32101
Evaluation  [16/82]  eta: 0:02:36  loss: 0.6458  acc: 0.6562  time: 2.3707  data: 0.0073  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6291  acc: 0.7188  time: 2.5752  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6802  acc: 0.6562  time: 2.5327  data: 0.0071  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6785  acc: 0.6406  time: 2.5198  data: 0.0074  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6595  acc: 0.6406  time: 2.5126  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4765  acc: 0.8125  time: 2.4123  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:24 (2.4898 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07767653465270996 uauc: 0.6351701193078974
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002508401870727539 u-nDCG: 0.8473905389961551
Metrics @10: AP=2.9696, Cov=0.3197, Gini=0.3578
Advanced @10: DivRatio=0.5100, ORRatio=0.0181, MGU=0.0000
rank_0 auc: 0.7093535751083304
Train: data epoch: [19]  [ 0/50]  eta: 0:00:26  lr: 0.000999  loss: 0.4984  time: 0.5377  data: 0.0000  max mem: 32101
Train: data epoch: [19]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.5139  time: 0.5387  data: 0.0000  max mem: 32101
Train: data epoch: [19] Total time: 0:00:26 (0.5387 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6203  acc: 0.6719  time: 1.5532  data: 0.0147  max mem: 32101
Evaluation  [16/82]  eta: 0:02:36  loss: 0.6672  acc: 0.5781  time: 2.3725  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6423  acc: 0.7031  time: 2.5668  data: 0.0074  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6034  acc: 0.7344  time: 2.5146  data: 0.0074  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6576  acc: 0.5938  time: 2.5114  data: 0.0073  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6587  acc: 0.5938  time: 2.5570  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5072  acc: 0.7500  time: 2.4580  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:24 (2.4915 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 2025-11-29 12:40:12,119 [INFO] Averaged stats: lr: 0.000998  loss: 0.458608
2025-11-29 12:40:12,119 [INFO] Evaluating on valid.
2025-11-29 12:40:12,123 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:43:36,301 [INFO] Averaged stats: loss: 0.658944  acc: 0.645960 ***auc: 0.6977930333841694 ***uauc: 0.6433141119946784 ***u-nDCG: 0.8507304946851175 ***AP@10: 2.999478114099184 ***Coverage@10: 0.31633906633906633 ***Gini@10: 0.3545473140427071 ***DivRatio@10: 0.5046545810877021 ***ORRatio@10: 0.021068103870651642 ***MGU@10: 0.0
2025-11-29 12:43:36,308 [INFO] Start training
2025-11-29 12:43:36,314 [INFO] Start training epoch 26, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:44:03,470 [INFO] Averaged stats: lr: 0.000998  loss: 0.430400
2025-11-29 12:44:03,472 [INFO] Evaluating on valid.
2025-11-29 12:44:03,476 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:47:27,098 [INFO] Averaged stats: loss: 0.638570  acc: 0.618902 ***auc: 0.7033382536079085 ***uauc: 0.6480088389828593 ***u-nDCG: 0.8472303580143388 ***AP@10: 2.9810555784933954 ***Coverage@10: 0.3194103194103194 ***Gini@10: 0.35125880978404256 ***DivRatio@10: 0.5095541401273885 ***ORRatio@10: 0.021068103870651642 ***MGU@10: 0.0
2025-11-29 12:47:27,105 [INFO] Start training
2025-11-29 12:47:27,112 [INFO] Start training epoch 27, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:47:54,423 [INFO] Averaged stats: lr: 0.000998  loss: 0.435246
2025-11-29 12:47:54,424 [INFO] Evaluating on valid.
2025-11-29 12:47:54,429 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:51:19,140 [INFO] Averaged stats: loss: 0.660882  acc: 0.608803 ***auc: 0.6930561616601971 ***uauc: 0.6681027357252607 ***u-nDCG: 0.8566857192968377 ***AP@10: 3.000248756889697 ***Coverage@10: 0.31971744471744473 ***Gini@10: 0.35433695693612366 ***DivRatio@10: 0.5100440960313571 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 12:51:19,148 [INFO] Start training
2025-11-29 12:51:19,154 [INFO] Start training epoch 28, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:51:46,576 [INFO] Averaged stats: lr: 0.000998  loss: 0.468762
2025-11-29 12:51:46,578 [INFO] Evaluating on valid.
2025-11-29 12:51:46,582 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:55:10,629 [INFO] Averaged stats: loss: 0.708732  acc: 0.600229 ***auc: 0.6960263672470967 ***uauc: 0.640645791724129 ***u-nDCG: 0.847316219678288 ***AP@10: 2.96314752710441 ***Coverage@10: 0.32893120393120395 ***Gini@10: 0.34258714101351795 ***DivRatio@10: 0.5247427731504165 ***ORRatio@10: 0.018128368446839783 ***MGU@10: 0.0
2025-11-29 12:55:10,634 [INFO] Start training
2025-11-29 12:55:10,641 [INFO] Start training epoch 29, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:55:37,945 [INFO] Averaged stats: lr: 0.000998  loss: 0.441388
2025-11-29 12:55:37,946 [INFO] Evaluating on valid.
2025-11-29 12:55:37,950 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 12:59:03,035 [INFO] Averaged stats: loss: 0.695083  acc: 0.583841 ***auc: 0.6631496429175443 ***uauc: 0.6305400110617582 ***u-nDCG: 0.845347238830336 ***AP@10: 2.943944938467686 ***Coverage@10: 0.3298525798525799 ***Gini@10: 0.3368697748301349 ***DivRatio@10: 0.5262126408623224 ***ORRatio@10: 0.020088192062714356 ***MGU@10: 0.0
2025-11-29 12:59:03,042 [INFO] Start training
2025-11-29 12:59:03,048 [INFO] Start training epoch 30, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 12:59:30,086 [INFO] Averaged stats: lr: 0.000998  loss: 0.422854
2025-11-29 12:59:30,086 [INFO] Evaluating on valid.
2025-11-29 12:59:30,091 [WARNING] item_category_dict not provided. MGU metric will be 0.
0.07514119148254395 uauc: 0.6628916968089883
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003080129623413086 u-nDCG: 0.8541911472817091
Metrics @10: AP=2.9975, Cov=0.3179, Gini=0.3549
Advanced @10: DivRatio=0.5071, ORRatio=0.0176, MGU=0.0000
rank_0 auc: 0.7165584785348875
Train: data epoch: [20]  [ 0/50]  eta: 0:00:25  lr: 0.000999  loss: 0.3812  time: 0.5101  data: 0.0000  max mem: 32101
Train: data epoch: [20]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.5111  time: 0.5416  data: 0.0000  max mem: 32101
Train: data epoch: [20] Total time: 0:00:27 (0.5446 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6601  acc: 0.5781  time: 1.5589  data: 0.0149  max mem: 32101
Evaluation  [16/82]  eta: 0:02:37  loss: 0.6861  acc: 0.6094  time: 2.3793  data: 0.0081  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6109  acc: 0.6406  time: 2.5754  data: 0.0073  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6767  acc: 0.6094  time: 2.5357  data: 0.0074  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7280  acc: 0.5781  time: 2.5090  data: 0.0077  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6770  acc: 0.5469  time: 2.4902  data: 0.0071  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5091  acc: 0.7500  time: 2.3906  data: 0.0067  max mem: 32101
Evaluation Total time: 0:03:23 (2.4819 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0764312744140625 uauc: 0.6418284083281226
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003068208694458008 u-nDCG: 0.8481347417356767
Metrics @10: AP=3.0217, Cov=0.3127, Gini=0.3632
Advanced @10: DivRatio=0.4988, ORRatio=0.0211, MGU=0.0000
rank_0 auc: 0.7038425062723477
Train: data epoch: [21]  [ 0/50]  eta: 0:00:27  lr: 0.000999  loss: 0.7864  time: 0.5422  data: 0.0000  max mem: 32101
Train: data epoch: [21]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.5812  time: 0.5428  data: 0.0000  max mem: 32101
Train: data epoch: [21] Total time: 0:00:27 (0.5448 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.6427  acc: 0.5938  time: 1.5778  data: 0.0147  max mem: 32101
Evaluation  [16/82]  eta: 0:02:37  loss: 0.6628  acc: 0.6250  time: 2.3788  data: 0.0079  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.5829  acc: 0.7344  time: 2.5381  data: 0.0073  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6302  acc: 0.6562  time: 2.5885  data: 0.0075  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7013  acc: 0.5625  time: 2.5572  data: 0.0071  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.7107  acc: 0.5938  time: 2.5053  data: 0.0073  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4495  acc: 0.7500  time: 2.4040  data: 0.0070  max mem: 32101
Evaluation Total time: 0:03:24 (2.4980 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07774162292480469 uauc: 0.6736427101464683
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003014087677001953 u-nDCG: 0.855808493845456
Metrics @10: AP=2.9976, Cov=0.3157, Gini=0.3622
Advanced @10: DivRatio=0.5037, ORRatio=0.0181, MGU=0.0000
rank_0 auc: 0.7104083332949749
Train: data epoch: [22]  [ 0/50]  eta: 0:00:25  lr: 0.000999  loss: 0.2509  time: 0.5043  data: 0.0000  max mem: 32101
Train: data epoch: [22]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.4600  time: 0.5531  data: 0.0000  max mem: 32101
Train: data epoch: [22] Total time: 0:00:27 (0.5467 s / it)
Evaluation  [ 0/82]  eta: 0:02:21  loss: 0.6145  acc: 0.5625  time: 1.7310  data: 0.0137  max mem: 32101
Evaluation  [16/82]  eta: 0:02:36  loss: 0.6577  acc: 0.6562  time: 2.3675  data: 0.0080  max mem: 32101
Evaluation  [32/82]  eta: 0:02:02  loss: 0.5694  acc: 0.6875  time: 2.5094  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:24  loss: 0.5738  acc: 0.6719  time: 2.5219  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6841  acc: 0.5312  time: 2.5781  data: 0.0074  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6708  acc: 0.6406  time: 2.4754  data: 0.0071  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4766  acc: 0.7500  time: 2.3775  data: 0.0068  max mem: 32101
Evaluation Total time: 0:03:23 (2.4798 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07383513450622559 uauc: 0.6487242382844411
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004045724868774414 u-nDCG: 0.8451466824124894
Metrics @10: AP=2.9697, Cov=0.3240, Gini=0.3519
Advanced @10: DivRatio=0.5169, ORRatio=0.0191, MGU=0.0000
rank_0 auc: 0.7148975332155655
Train: data epoch: [23]  [ 0/50]  eta: 0:00:27  lr: 0.000999  loss: 0.3674  time: 0.5513  data: 0.0000  max mem: 32101
Train: data epoch: [23]  [49/50]  eta: 0:00:00  lr: 0.000999  loss: 0.3348  time: 0.5427  data: 0.0000  max mem: 32101
Train: data epoch: [23] Total time: 0:00:27 (0.5435 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.6279  acc: 0.6094  time: 1.5797  data: 0.0136  max mem: 32101
Evaluation  [16/82]  eta: 0:02:39  loss: 0.6275  acc: 0.7188  time: 2.4183  data: 0.0079  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6310  acc: 0.6875  time: 2.5154  data: 0.0073  max mem: 32101
Evaluation  [48/82]  eta: 0:01:24  loss: 0.6353  acc: 0.6406  time: 2.5117  data: 0.0075  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6893  acc: 0.6094  time: 2.5640  data: 0.0073  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6181  acc: 0.6875  time: 2.4810  data: 0.0071  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4227  acc: 0.7500  time: 2.3820  data: 0.0067  max mem: 32101
Evaluation Total time: 0:03:23 (2.4813 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0777130126953125 uauc: 0.6712633664789895
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0020389556884765625 u-nDCG: 0.8590396853657598
Metrics @10: AP=3.0157, Cov=0.3120, Gini=0.3637
Advanced @10: DivRatio=0.4978, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7194931963753797
Train: data epoch: [24]  [ 0/50]  eta: 0:00:25  lr: 0.000999  loss: 0.6066  time: 0.5091  data: 0.0000  max mem: 32101
Train: data epoch: [24]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.3838  time: 0.5420  data: 0.0000  max mem: 32101
Train: data epoch: [24] Total time: 0:00:27 (0.5421 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.6035  acc: 0.5938  time: 1.5751  data: 0.0153  max mem: 32101
Evaluation  [16/82]  eta: 0:02:39  loss: 0.6543  acc: 0.6250  time: 2.4216  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.5602  acc: 0.7188  time: 2.5607  data: 0.0073  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6416  acc: 0.5000  time: 2.5435  data: 0.0075  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6871  acc: 0.5781  time: 2.5733  data: 0.0073  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6643  acc: 0.5781  time: 2.4986  data: 0.0071  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5041  acc: 0.7500  time: 2.3947  data: 0.0067  max mem: 32101
Evaluation Total time: 0:03:25 (2.5008 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07578349113464355 uauc: 0.6664999854451639
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003069162368774414 u-nDCG: 0.8628745282036524
Metrics @10: AP=3.0135, Cov=0.3133, Gini=0.3644
Advanced @10: DivRatio=0.4998, ORRatio=0.0201, MGU=0.0000
rank_0 auc: 0.7128497863088274
Train: data epoch: [25]  [ 0/50]  eta: 0:00:26  lr: 0.000998  loss: 0.4800  time: 0.5398  data: 0.0000  max mem: 32101
2025-11-29 13:02:55,059 [INFO] Averaged stats: loss: 0.658991  acc: 0.615091 ***auc: 0.6963623872057616 ***uauc: 0.6242010559492398 ***u-nDCG: 0.8412524139767362 ***AP@10: 2.939798749499234 ***Coverage@10: 0.33046683046683045 ***Gini@10: 0.33810235889178897 ***DivRatio@10: 0.5271925526702597 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 13:02:55,066 [INFO] Start training
2025-11-29 13:02:55,072 [INFO] Start training epoch 31, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 13:03:22,403 [INFO] Averaged stats: lr: 0.000998  loss: 0.424020
2025-11-29 13:03:22,405 [INFO] Evaluating on valid.
2025-11-29 13:03:22,409 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 13:06:46,989 [INFO] Averaged stats: loss: 0.711498  acc: 0.605183 ***auc: 0.7090889018532176 ***uauc: 0.655348575012716 ***u-nDCG: 0.8525734539145844 ***AP@10: 2.977795434980673 ***Coverage@10: 0.3194103194103194 ***Gini@10: 0.3507547205366902 ***DivRatio@10: 0.5095541401273885 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-29 13:06:46,996 [INFO] Start training
2025-11-29 13:06:47,003 [INFO] Start training epoch 32, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 13:07:14,061 [INFO] Averaged stats: lr: 0.000997  loss: 0.454389
2025-11-29 13:07:14,062 [INFO] Evaluating on valid.
2025-11-29 13:07:14,066 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 13:10:37,966 [INFO] Averaged stats: loss: 0.679247  acc: 0.601944 ***auc: 0.685915106480315 ***uauc: 0.6656513754685018 ***u-nDCG: 0.858004763519658 ***AP@10: 2.999357242215106 ***Coverage@10: 0.3181818181818182 ***Gini@10: 0.35317024170527367 ***DivRatio@10: 0.507594316511514 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-29 13:10:37,973 [INFO] Start training
2025-11-29 13:10:37,979 [INFO] Start training epoch 33, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 13:11:05,204 [INFO] Averaged stats: lr: 0.000997  loss: 0.433729
2025-11-29 13:11:05,206 [INFO] Evaluating on valid.
2025-11-29 13:11:05,210 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 13:14:29,855 [INFO] Averaged stats: loss: 0.667682  acc: 0.631479 ***auc: 0.7025670261817902 ***uauc: 0.6489273734088693 ***u-nDCG: 0.850493639333978 ***AP@10: 2.96237559965731 ***Coverage@10: 0.32217444717444715 ***Gini@10: 0.3492320676839752 ***DivRatio@10: 0.5139637432631063 ***ORRatio@10: 0.021068103870651642 ***MGU@10: 0.0
2025-11-29 13:14:29,863 [INFO] Start training
2025-11-29 13:14:29,869 [INFO] Start training epoch 34, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-29 13:14:57,149 [INFO] Averaged stats: lr: 0.000997  loss: 0.419950
2025-11-29 13:14:57,150 [INFO] Evaluating on valid.
2025-11-29 13:14:57,155 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-29 13:18:21,401 [INFO] Averaged stats: loss: 0.697857  acc: 0.564787 ***auc: 0.687570780607179 ***uauc: 0.6347555229607476 ***u-nDCG: 0.844247984873955 ***AP@10: 2.926077327467158 ***Coverage@10: 0.33292383292383293 ***Gini@10: 0.34263375705780563 ***DivRatio@10: 0.5311121999020089 ***ORRatio@10: 0.020088192062714356 ***MGU@10: 0.0
2025-11-29 13:18:21,405 [INFO] Early stop. The results has not changed up to 20 epochs.
2025-11-29 13:18:21,405 [INFO] Training time 2:16:58
Train: data epoch: [25]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.2358  time: 0.5462  data: 0.0000  max mem: 32101
Train: data epoch: [25] Total time: 0:00:27 (0.5426 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6283  acc: 0.6719  time: 1.5582  data: 0.0138  max mem: 32101
Evaluation  [16/82]  eta: 0:02:42  loss: 0.7291  acc: 0.5938  time: 2.4696  data: 0.0076  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6819  acc: 0.6094  time: 2.5989  data: 0.0069  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6585  acc: 0.6719  time: 2.4902  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7323  acc: 0.5781  time: 2.5614  data: 0.0075  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.7290  acc: 0.5938  time: 2.5276  data: 0.0073  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5600  acc: 0.6250  time: 2.4265  data: 0.0070  max mem: 32101
Evaluation Total time: 0:03:24 (2.4882 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08128666877746582 uauc: 0.6433141119946784
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030164718627929688 u-nDCG: 0.8507304946851175
Metrics @10: AP=2.9995, Cov=0.3163, Gini=0.3545
Advanced @10: DivRatio=0.5047, ORRatio=0.0211, MGU=0.0000
rank_0 auc: 0.6977930333841694
Train: data epoch: [26]  [ 0/50]  eta: 0:00:26  lr: 0.000998  loss: 0.3250  time: 0.5263  data: 0.0000  max mem: 32101
Train: data epoch: [26]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.6301  time: 0.5421  data: 0.0000  max mem: 32101
Train: data epoch: [26] Total time: 0:00:27 (0.5431 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.6141  acc: 0.6250  time: 1.5587  data: 0.0132  max mem: 32101
Evaluation  [16/82]  eta: 0:02:36  loss: 0.6791  acc: 0.6250  time: 2.3686  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.5898  acc: 0.6875  time: 2.5521  data: 0.0072  max mem: 32101
Evaluation  [48/82]  eta: 0:01:24  loss: 0.6437  acc: 0.5781  time: 2.5170  data: 0.0074  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6718  acc: 0.5625  time: 2.4984  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6598  acc: 0.5625  time: 2.5322  data: 0.0068  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5293  acc: 0.7500  time: 2.4328  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:23 (2.4814 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0798797607421875 uauc: 0.6480088389828593
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003198862075805664 u-nDCG: 0.8472303580143388
Metrics @10: AP=2.9811, Cov=0.3194, Gini=0.3513
Advanced @10: DivRatio=0.5096, ORRatio=0.0211, MGU=0.0000
rank_0 auc: 0.7033382536079085
Train: data epoch: [27]  [ 0/50]  eta: 0:00:27  lr: 0.000998  loss: 0.3383  time: 0.5526  data: 0.0000  max mem: 32101
Train: data epoch: [27]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.4881  time: 0.5461  data: 0.0000  max mem: 32101
Train: data epoch: [27] Total time: 0:00:27 (0.5462 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.6371  acc: 0.6250  time: 1.5794  data: 0.0137  max mem: 32101
Evaluation  [16/82]  eta: 0:02:38  loss: 0.5953  acc: 0.6406  time: 2.4063  data: 0.0076  max mem: 32101
Evaluation  [32/82]  eta: 0:02:05  loss: 0.6493  acc: 0.6719  time: 2.5907  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.7126  acc: 0.6094  time: 2.5414  data: 0.0071  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7347  acc: 0.5312  time: 2.5122  data: 0.0076  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6255  acc: 0.6406  time: 2.5030  data: 0.0074  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4698  acc: 0.6875  time: 2.4026  data: 0.0070  max mem: 32101
Evaluation Total time: 0:03:24 (2.4947 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07999563217163086 uauc: 0.6681027357252607
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003021240234375 u-nDCG: 0.8566857192968377
Metrics @10: AP=3.0002, Cov=0.3197, Gini=0.3543
Advanced @10: DivRatio=0.5100, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.6930561616601971
Train: data epoch: [28]  [ 0/50]  eta: 0:00:26  lr: 0.000998  loss: 0.2717  time: 0.5339  data: 0.0000  max mem: 32101
Train: data epoch: [28]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.2736  time: 0.5471  data: 0.0000  max mem: 32101
Train: data epoch: [28] Total time: 0:00:27 (0.5484 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.7408  acc: 0.5781  time: 1.5772  data: 0.0148  max mem: 32101
Evaluation  [16/82]  eta: 0:02:38  loss: 0.6393  acc: 0.6719  time: 2.3945  data: 0.0077  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6587  acc: 0.6719  time: 2.5415  data: 0.0072  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.7325  acc: 0.6094  time: 2.5762  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7583  acc: 0.5469  time: 2.5180  data: 0.0075  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6707  acc: 0.6562  time: 2.4788  data: 0.0071  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4125  acc: 0.6875  time: 2.3794  data: 0.0067  max mem: 32101
Evaluation Total time: 0:03:23 (2.4867 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07827329635620117 uauc: 0.640645791724129
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002521991729736328 u-nDCG: 0.847316219678288
Metrics @10: AP=2.9631, Cov=0.3289, Gini=0.3426
Advanced @10: DivRatio=0.5247, ORRatio=0.0181, MGU=0.0000
rank_0 auc: 0.6960263672470967
Train: data epoch: [29]  [ 0/50]  eta: 0:00:25  lr: 0.000998  loss: 0.4028  time: 0.5078  data: 0.0000  max mem: 32101
Train: data epoch: [29]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.3893  time: 0.5441  data: 0.0000  max mem: 32101
Train: data epoch: [29] Total time: 0:00:27 (0.5461 s / it)
Evaluation  [ 0/82]  eta: 0:02:22  loss: 0.6543  acc: 0.5938  time: 1.7376  data: 0.0128  max mem: 32101
Evaluation  [16/82]  eta: 0:02:40  loss: 0.6659  acc: 0.5625  time: 2.4248  data: 0.0078  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6979  acc: 0.6562  time: 2.5492  data: 0.0072  max mem: 32101
Evaluation  [48/82]  eta: 0:01:26  loss: 0.7191  acc: 0.5781  time: 2.5709  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6977  acc: 0.5469  time: 2.5684  data: 0.0074  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6184  acc: 0.6406  time: 2.4832  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4559  acc: 0.7500  time: 2.3837  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:24 (2.4993 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07508468627929688 uauc: 0.6305400110617582
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004096269607543945 u-nDCG: 0.845347238830336
Metrics @10: AP=2.9439, Cov=0.3299, Gini=0.3369
Advanced @10: DivRatio=0.5262, ORRatio=0.0201, MGU=0.0000
rank_0 auc: 0.6631496429175443
Train: data epoch: [30]  [ 0/50]  eta: 0:00:24  lr: 0.000998  loss: 0.5783  time: 0.4987  data: 0.0000  max mem: 32101
Train: data epoch: [30]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.6213  time: 0.5366  data: 0.0000  max mem: 32101
Train: data epoch: [30] Total time: 0:00:27 (0.5407 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6674  acc: 0.5938  time: 1.5683  data: 0.0133  max mem: 32101
Evaluation  [16/82]  eta: 0:02:43  loss: 0.6880  acc: 0.6719  time: 2.4746  data: 0.0073  max mem: 32101
Evaluation  [32/82]  eta: 0:02:05  loss: 0.6488  acc: 0.6406  time: 2.5598  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:26  loss: 0.5951  acc: 0.6250  time: 2.5299  data: 0.0074  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6758  acc: 0.6094  time: 2.5398  data: 0.0072  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6901  acc: 0.5625  time: 2.4657  data: 0.0069  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5710  acc: 0.7500  time: 2.3658  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:24 (2.4979 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07855033874511719 uauc: 0.6242010559492398
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003139019012451172 u-nDCG: 0.8412524139767362
Metrics @10: AP=2.9398, Cov=0.3305, Gini=0.3381
Advanced @10: DivRatio=0.5272, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.6963623872057616
Train: data epoch: [31]  [ 0/50]  eta: 0:00:26  lr: 0.000998  loss: 0.5086  time: 0.5205  data: 0.0000  max mem: 32101
Train: data epoch: [31]  [49/50]  eta: 0:00:00  lr: 0.000998  loss: 0.6037  time: 0.5444  data: 0.0000  max mem: 32101
Train: data epoch: [31] Total time: 0:00:27 (0.5466 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.7964  acc: 0.6094  time: 1.5498  data: 0.0156  max mem: 32101
Evaluation  [16/82]  eta: 0:02:38  loss: 0.6471  acc: 0.6562  time: 2.4056  data: 0.0080  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6408  acc: 0.7188  time: 2.5345  data: 0.0074  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6938  acc: 0.5938  time: 2.5321  data: 0.0071  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7698  acc: 0.5781  time: 2.5596  data: 0.0074  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6816  acc: 0.6250  time: 2.5196  data: 0.0073  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5440  acc: 0.6875  time: 2.4151  data: 0.0066  max mem: 32101
Evaluation Total time: 0:03:24 (2.4932 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07611393928527832 uauc: 0.655348575012716
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030279159545898438 u-nDCG: 0.8525734539145844
Metrics @10: AP=2.9778, Cov=0.3194, Gini=0.3508
Advanced @10: DivRatio=0.5096, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7090889018532176
Train: data epoch: [32]  [ 0/50]  eta: 0:00:26  lr: 0.000998  loss: 0.1766  time: 0.5320  data: 0.0000  max mem: 32101
Train: data epoch: [32]  [49/50]  eta: 0:00:00  lr: 0.000997  loss: 0.4719  time: 0.5409  data: 0.0000  max mem: 32101
Train: data epoch: [32] Total time: 0:00:27 (0.5412 s / it)
Evaluation  [ 0/82]  eta: 0:02:08  loss: 0.6785  acc: 0.5625  time: 1.5642  data: 0.0147  max mem: 32101
Evaluation  [16/82]  eta: 0:02:40  loss: 0.6927  acc: 0.6250  time: 2.4356  data: 0.0077  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.5982  acc: 0.6875  time: 2.5560  data: 0.0075  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.7379  acc: 0.5625  time: 2.5218  data: 0.0074  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.6975  acc: 0.5312  time: 2.5230  data: 0.0075  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6204  acc: 0.6406  time: 2.5220  data: 0.0069  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.5505  acc: 0.8125  time: 2.4231  data: 0.0065  max mem: 32101
Evaluation Total time: 0:03:23 (2.4849 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07926273345947266 uauc: 0.6656513754685018
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030493736267089844 u-nDCG: 0.858004763519658
Metrics @10: AP=2.9994, Cov=0.3182, Gini=0.3532
Advanced @10: DivRatio=0.5076, ORRatio=0.0191, MGU=0.0000
rank_0 auc: 0.685915106480315
Train: data epoch: [33]  [ 0/50]  eta: 0:00:25  lr: 0.000997  loss: 0.4268  time: 0.5111  data: 0.0000  max mem: 32101
Train: data epoch: [33]  [49/50]  eta: 0:00:00  lr: 0.000997  loss: 0.2549  time: 0.5442  data: 0.0000  max mem: 32101
Train: data epoch: [33] Total time: 0:00:27 (0.5445 s / it)
Evaluation  [ 0/82]  eta: 0:02:09  loss: 0.7288  acc: 0.5938  time: 1.5769  data: 0.0148  max mem: 32101
Evaluation  [16/82]  eta: 0:02:37  loss: 0.6893  acc: 0.6406  time: 2.3809  data: 0.0076  max mem: 32101
Evaluation  [32/82]  eta: 0:02:04  loss: 0.6356  acc: 0.6875  time: 2.5629  data: 0.0071  max mem: 32101
Evaluation  [48/82]  eta: 0:01:25  loss: 0.6353  acc: 0.6094  time: 2.5276  data: 0.0072  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7568  acc: 0.5312  time: 2.5192  data: 0.0074  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.7225  acc: 0.5938  time: 2.5509  data: 0.0070  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.6026  acc: 0.8125  time: 2.4488  data: 0.0067  max mem: 32101
Evaluation Total time: 0:03:24 (2.4940 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07526898384094238 uauc: 0.6489273734088693
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030286312103271484 u-nDCG: 0.850493639333978
Metrics @10: AP=2.9624, Cov=0.3222, Gini=0.3492
Advanced @10: DivRatio=0.5140, ORRatio=0.0211, MGU=0.0000
rank_0 auc: 0.7025670261817902
Train: data epoch: [34]  [ 0/50]  eta: 0:00:29  lr: 0.000997  loss: 0.6989  time: 0.5968  data: 0.0000  max mem: 32101
Train: data epoch: [34]  [49/50]  eta: 0:00:00  lr: 0.000997  loss: 0.3939  time: 0.5460  data: 0.0000  max mem: 32101
Train: data epoch: [34] Total time: 0:00:27 (0.5456 s / it)
Evaluation  [ 0/82]  eta: 0:02:07  loss: 0.7235  acc: 0.5000  time: 1.5602  data: 0.0148  max mem: 32101
Evaluation  [16/82]  eta: 0:02:35  loss: 0.7307  acc: 0.5469  time: 2.3485  data: 0.0075  max mem: 32101
Evaluation  [32/82]  eta: 0:02:03  loss: 0.6280  acc: 0.6875  time: 2.5536  data: 0.0069  max mem: 32101
Evaluation  [48/82]  eta: 0:01:24  loss: 0.6710  acc: 0.5625  time: 2.5321  data: 0.0073  max mem: 32101
Evaluation  [64/82]  eta: 0:00:45  loss: 0.7434  acc: 0.5781  time: 2.5339  data: 0.0070  max mem: 32101
Evaluation  [80/82]  eta: 0:00:05  loss: 0.7132  acc: 0.5625  time: 2.5493  data: 0.0067  max mem: 32101
Evaluation  [81/82]  eta: 0:00:02  loss: 0.7305  acc: 0.6250  time: 2.4487  data: 0.0063  max mem: 32101
Evaluation Total time: 0:03:24 (2.4891 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07581233978271484 uauc: 0.6347555229607476
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003046274185180664 u-nDCG: 0.844247984873955
Metrics @10: AP=2.9261, Cov=0.3329, Gini=0.3426
Advanced @10: DivRatio=0.5311, ORRatio=0.0201, MGU=0.0000
rank_0 auc: 0.687570780607179
