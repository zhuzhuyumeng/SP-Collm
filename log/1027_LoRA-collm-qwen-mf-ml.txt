W1128 21:50:36.174313 30700 site-packages\torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
2025-11-28 21:50:36,186 [INFO] Building datasets...
2025-11-28 21:50:36,377 [INFO] Movie OOD datasets, max history length:10
2025-11-28 21:50:36,406 [INFO] Movie OOD datasets, max history length:10
2025-11-28 21:50:36,564 [INFO] Movie OOD datasets, max history length:10
2025-11-28 21:50:36,709 [INFO] 
=====  Running Parameters    =====
2025-11-28 21:50:36,709 [INFO] {
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_url": "env://",
    "distributed": false,
    "evaluate": false,
    "init_lr": 0.001,
    "iters_per_epoch": 50,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1000,
    "min_lr": 1e-05,
    "mode": "v2",
    "num_workers": 0,
    "output_dir": "Qwen/Qwen2.5-1.5rec_log/collm",
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "rec_pretrain",
    "test_splits": [
        "test",
        "valid"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "valid"
    ],
    "warmup_lr": 1e-05,
    "warmup_steps": 200,
    "weight_decay": 0.001,
    "world_size": 1
}
2025-11-28 21:50:36,710 [INFO] 
======  Dataset Attributes  ======
2025-11-28 21:50:36,710 [INFO] 
======== movie_ood =======
2025-11-28 21:50:36,710 [INFO] {
    "build_info": {
        "storage": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
    },
    "data_type": "default",
    "path": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
}
2025-11-28 21:50:36,710 [INFO] 
======  Model Attributes  ======
2025-11-28 21:50:36,710 [INFO] {
    "ans_type": "v2",
    "arch": "mini_gpt4rec_v2",
    "ckpt": "minigpt4/Qwen/Qwen2.5-1.5rec_log/collm/20251112212_best_tallrec/checkpoint_best.pth",
    "end_sym": "###",
    "freeze_lora": true,
    "freeze_proj": false,
    "freeze_rec": true,
    "item_num": -100,
    "llama_model": "Qwen/Qwen2-1.5B",
    "lora_config": {
        "alpha": 16,
        "dropout": 0.05,
        "r": 8,
        "target_modules": [
            "q_proj",
            "v_proj"
        ],
        "use_lora": true
    },
    "max_txt_len": 1024,
    "model_type": "pretrain_vicuna",
    "proj_drop": 0,
    "proj_mid_times": 10,
    "proj_token_num": 1,
    "prompt_path": "prompts/collm_movie.txt",
    "prompt_template": "{}",
    "rec_config": {
        "embedding_size": 256,
        "item_num": 3256,
        "pretrained_path": "collm-trained-models/my-collm-trained-models/mf_0912_ml1m_oodv2_best_model_d256lr-0.001wd0.0001.pth",
        "user_num": 839
    },
    "rec_model": "MF",
    "user_num": -100
}
2025-11-28 21:50:36,724 [INFO] freeze rec encoder
`torch_dtype` is deprecated! Use `dtype` instead!

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
binary_path: D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll
CUDA SETUP: Loading binary D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll...
Not using distributed mode
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\train data size: (33891, 7)
Movie OOD datasets, max history length: 10
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\valid_small data size: (5200, 7)
Movie OOD datasets, max history length: 10
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\test data size: (7331, 7)
Movie OOD datasets, max history length: 10
data dir: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\
正在计算全局流行度以进行偏见评估...
已计算 3087 个物品的流行度。总物品数为 3256。
正在将流行度数据注入评估任务...
runing MiniGPT4Rec_v2 ...... 
Loading Rec_model
### rec_encoder: MF
creat MF model, user num: 839 item num: 3256
successfully load the pretrained model......
freeze rec encoder
Loading Rec_model Done
Loading LLama model: Qwen/Qwen2-1.5B
Loading LLAMA Done
Setting Lora
Setting Lora Done
freeze lora...
type: <class 'int'> 10
Load 4 training prompts
Prompt List: 
['#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user\'s preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> with the feature <TargetItemID>? Answer with "Yes" or "No". \\n#Answer:']
Load MiniGPT4Rec Checkpoint: minigpt4/Qwen/Qwen2.5-1.5rec_log/collm/20251112212_best_tallrec/checkpoint_best.pth
loading message, msg.... 
 _IncompatibleKeys(missing_keys=['rec_encoder.user_embedding.weight', 'rec_encoder.item_embedding.weight', 'llama_model.base_model.model.model.embed_tokens.weight', 'llama_model.base_model.model.model.layers.0.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.0.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.0.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.0.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.0.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.0.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.0.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.0.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.0.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.0.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.0.input_layernorm.weight', 'llama_model.base_model.model.model.layers.0.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.1.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.1.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.1.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.1.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.1.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.1.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.1.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.1.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.1.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.1.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.1.input_layernorm.weight', 'llama_model.base_model.model.model.layers.1.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.2.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.2.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.2.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.2.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.2.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.2.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.2.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.2.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.2.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.2.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.2.input_layernorm.weight', 'llama_model.base_model.model.model.layers.2.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.3.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.3.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.3.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.3.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.3.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.3.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.3.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.3.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.3.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.3.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.3.input_layernorm.weight', 'llama_model.base_model.model.model.layers.3.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.4.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.4.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.4.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.4.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.4.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.4.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.4.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.4.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.4.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.4.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.4.input_layernorm.weight', 'llama_model.base_model.model.model.layers.4.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.5.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.5.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.5.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.5.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.5.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.5.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.5.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.5.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.5.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.5.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.5.input_layernorm.weight', 'llama_model.base_model.model.model.layers.5.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.6.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.6.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.6.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.6.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.6.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.6.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.6.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.6.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.6.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.6.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.6.input_layernorm.weight', 'llama_model.base_model.model.model.layers.6.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.7.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.7.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.7.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.7.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.7.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.7.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.7.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.7.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.7.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.7.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.7.input_layernorm.weight', 'llama_model.base_model.model.model.layers.7.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.8.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.8.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.8.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.8.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.8.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.8.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.8.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.8.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.8.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.8.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.8.input_layernorm.weight', 'llama_model.base_model.model.model.layers.8.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.9.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.9.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.9.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.9.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.9.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.9.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.9.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.9.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.9.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.9.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.9.input_layernorm.weight', 'llama_model.base_model.model.model.layers.9.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.10.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.10.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.10.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.10.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.10.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.10.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.10.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.10.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.10.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.10.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.10.input_layernorm.weight', 'llama_model.base_model.model.model.layers.10.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.11.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.11.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.11.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.11.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.11.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.11.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.11.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.11.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.11.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.11.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.11.input_layernorm.weight', 'llama_model.base_model.model.model.layers.11.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.12.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.12.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.12.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.12.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.12.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.12.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.12.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.12.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.12.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.12.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.12.input_layernorm.weight', 'llama_model.base_model.model.model.layers.12.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.13.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.13.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.13.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.13.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.13.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.13.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.13.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.13.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.13.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.13.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.13.input_layernorm.weight', 'llama_model.base_model.model.model.layers.13.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.14.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.14.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.14.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.14.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.14.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.14.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.14.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.14.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.14.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.14.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.14.input_layernorm.weight', 'llama_model.base_model.model.model.layers.14.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.15.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.15.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.15.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.15.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.15.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.15.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.15.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.15.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.15.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.15.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.15.input_layernorm.weight', 'llama_model.base_model.model.model.layers.15.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.16.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.16.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.16.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.16.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.16.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.16.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.16.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.16.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.16.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.16.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.16.input_layernorm.weight', 'llama_model.base_model.model.model.layers.16.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.17.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.17.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.17.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.17.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.17.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.17.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.17.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.17.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.17.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.17.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.17.input_layernorm.weight', 'llama_model.base_model.model.model.layers.17.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.18.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.18.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.18.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.18.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.18.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.18.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.18.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.18.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.18.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.18.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.18.input_layernorm.weight', 'llama_model.base_model.model.model.layers.18.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.19.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.19.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.19.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.19.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.19.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.19.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.19.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.19.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.19.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.19.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.19.input_layernorm.weight', 'llama_model.base_model.model.model.layers.19.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.20.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.20.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.20.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.20.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.20.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.20.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.20.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.20.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.20.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.20.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.20.input_layernorm.weight', 'llama_model.base_model.model.model.layers.20.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.21.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.21.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.21.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.21.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.21.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.21.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.21.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.21.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.21.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.21.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.21.input_layernorm.weight', 'llama_model.base_model.model.model.layers.21.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.22.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.22.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.22.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.22.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.22.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.22.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.22.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.22.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.22.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.22.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.22.input_layernorm.weight', 'llama_model.base_model.model.model.layers.22.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.23.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.23.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.23.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.23.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.23.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.23.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.23.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.23.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.23.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.23.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.23.input_layernorm.weight', 'llama_model.base_model.model.model.layers.23.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.24.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.24.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.24.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.24.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.24.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.24.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.24.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.24.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.24.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.24.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.24.input_layernorm.weight', 'llama_model.base_model.model.model.layers.24.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.25.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.25.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.25.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.25.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.25.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.25.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.25.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.25.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.25.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.25.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.25.input_layernorm.weight', 'llama_model.base_model.model.model.layers.25.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.26.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.26.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.26.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.26.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.26.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.26.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.26.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.26.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.26.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.26.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.26.input_layernorm.weight', 'llama_model.base_model.model.model.layers.26.post_attention_layernorm.weight', 'llama_model.base_model.model.model.layers.27.self_attn.q_proj.weight', 'llama_model.base_model.model.model.layers.27.self_attn.q_proj.bias', 'llama_model.base_model.model.model.layers.27.self_attn.k_proj.weight', 'llama_model.base_model.model.model.layers.27.self_attn.k_proj.bias', 'llama_model.base_model.model.model.layers.27.self_attn.v_proj.weight', 'llama_model.base_model.model.model.layers.27.self_attn.v_proj.bias', 'llama_model.base_model.model.model.layers.27.self_attn.o_proj.weight', 'llama_model.base_model.model.model.layers.27.mlp.gate_proj.weight', 'llama_model.base_model.model.model.layers.27.mlp.up_proj.weight', 'llama_model.base_model.model.model.layers.27.mlp.down_proj.weight', 'llama_model.base_model.model.model.layers.27.input_layernorm.weight', 'llama_model.base_model.model.model.layers.27.post_attention_layernorm.weight', 'llama_model.base_model.model.model.norm.weight', 'llama_proj.0.weight', 'llama_proj.0.bias', 'llama_proj.2.weight', 'llama_proj.2.bias'], unexpected_keys=[])2025-11-28 21:50:39,749 [INFO] Start training
2025-11-28 21:50:39,755 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2025-11-28 21:50:39,755 [INFO] Loaded 33891 records for train split from the dataset.
2025-11-28 21:50:39,755 [INFO] Loaded 5200 records for valid split from the dataset.
2025-11-28 21:50:39,755 [INFO] Loaded 7331 records for test split from the dataset.
2025-11-28 21:50:39,759 [INFO] number of trainable parameters: 4591616
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\runners\runner_base.py:153: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
2025-11-28 21:50:39,761 [INFO] Start training epoch 0, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 21:51:07,021 [INFO] Averaged stats: lr: 0.000131  loss: 0.576930
2025-11-28 21:51:07,023 [INFO] Evaluating on valid.
2025-11-28 21:51:07,027 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 21:54:21,244 [INFO] Averaged stats: loss: 0.655007  acc: 0.654916 ***auc: 0.6983865993518067 ***uauc: 0.6581281859094846 ***u-nDCG: 0.8567996149928117 ***AP@10: 3.036702987911534 ***Coverage@10: 0.3058968058968059 ***Gini@10: 0.3693628015245696 ***DivRatio@10: 0.48799608035276826 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-28 21:54:21,249 [INFO] Saving checkpoint at epoch 0 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251128215\checkpoint_best.pth.
2025-11-28 21:54:21,685 [INFO] Start training
2025-11-28 21:54:21,691 [INFO] Start training epoch 1, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 21:54:48,858 [INFO] Averaged stats: lr: 0.000131  loss: 0.567046
2025-11-28 21:54:48,860 [INFO] Evaluating on valid.
2025-11-28 21:54:48,864 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 21:58:31,434 [INFO] Averaged stats: loss: 0.639898  acc: 0.658727 ***auc: 0.7063810680148644 ***uauc: 0.6639749491411188 ***u-nDCG: 0.8564850575597747 ***AP@10: 3.0307348914689705 ***Coverage@10: 0.30651105651105653 ***Gini@10: 0.36813754898331696 ***DivRatio@10: 0.48897599216070553 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-28 21:58:31,441 [INFO] Saving checkpoint at epoch 1 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251128215\checkpoint_best.pth.
2025-11-28 21:58:31,935 [INFO] Start training
2025-11-28 21:58:31,943 [INFO] Start training epoch 2, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 21:58:58,646 [INFO] Averaged stats: lr: 0.000131  loss: 0.519109
2025-11-28 21:58:58,648 [INFO] Evaluating on valid.
2025-11-28 21:58:58,652 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:02:41,526 [INFO] Averaged stats: loss: 0.621743  acc: 0.647294 ***auc: 0.7177403392777041 ***uauc: 0.6634068194874201 ***u-nDCG: 0.8563146063055898 ***AP@10: 3.020872618507418 ***Coverage@10: 0.30896805896805896 ***Gini@10: 0.3660155675452431 ***DivRatio@10: 0.4928956393924547 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-28 22:02:41,540 [INFO] Saving checkpoint at epoch 2 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251128215\checkpoint_best.pth.
2025-11-28 22:02:42,530 [INFO] Start training
2025-11-28 22:02:42,551 [INFO] Start training epoch 3, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:03:13,497 [INFO] Averaged stats: lr: 0.000131  loss: 0.532644
2025-11-28 22:03:13,503 [INFO] Evaluating on valid.
2025-11-28 22:03:13,523 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:06:59,031 [INFO] Averaged stats: loss: 0.632818  acc: 0.600991 ***auc: 0.7125797676191093 ***uauc: 0.6768867724724239 ***u-nDCG: 0.8646979542430564 ***AP@10: 3.0327443551563866 ***Coverage@10: 0.3055896805896806 ***Gini@10: 0.37048200335336656 ***DivRatio@10: 0.4875061244487996 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-28 22:06:59,050 [INFO] Start training
2025-11-28 22:06:59,067 [INFO] Start training epoch 4, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:07:28,956 [INFO] Averaged stats: lr: 0.001000  loss: 0.594702
2025-11-28 22:07:28,959 [INFO] Evaluating on valid.
2025-11-28 22:07:28,971 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:11:15,261 [INFO] Averaged stats: loss: 0.628890  acc: 0.648628 ***auc: 0.7065169311444175 ***uauc: 0.6631063275123615 ***u-nDCG: 0.8556488494485736 ***AP@10: 3.020019992733203 ***Coverage@10: 0.3092751842751843 ***Gini@10: 0.3664544173149541 ***DivRatio@10: 0.49338559529642334 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-28 22:11:15,278 [INFO] Start training
2025-11-28 22:11:15,294 [INFO] Start training epoch 5, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:11:45,851 [INFO] Averaged stats: lr: 0.001000  loss: 0.530371
2025-11-28 22:11:45,856 [INFO] Evaluating on valid.
2025-11-28 22:11:45,874 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:15:28,920 [INFO] Averaged stats: loss: 0.628926  acc: 0.654916 ***auc: 0.7112056197147943 ***uauc: 0.66393831629584 ***u-nDCG: 0.857781032480325 ***AP@10: 3.0359471206016684 ***Coverage@10: 0.3055896805896806 ***Gini@10: 0.36715424255033136 ***DivRatio@10: 0.4875061244487996 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-28 22:15:28,944 [INFO] Start training
2025-11-28 22:15:28,976 [INFO] Start training epoch 6, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:15:59,607 [INFO] Averaged stats: lr: 0.001000  loss: 0.540137
2025-11-28 22:15:59,615 [INFO] Evaluating on valid.
2025-11-28 22:15:59,639 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:19:42,253 [INFO] Averaged stats: loss: 0.624050  acc: 0.628430 ***auc: 0.7138555446782561 ***uauc: 0.6705073918433752 ***u-nDCG: 0.8614299409173993 ***AP@10: 3.048005911422584 ***Coverage@10: 0.3046683046683047 ***Gini@10: 0.3678748952916818 ***DivRatio@10: 0.48603625673689366 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-28 22:19:42,274 [INFO] Start training
2025-11-28 22:19:42,291 [INFO] Start training epoch 7, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:20:12,593 [INFO] Averaged stats: lr: 0.001000  loss: 0.526646
2025-11-28 22:20:12,594 [INFO] Evaluating on valid.
2025-11-28 22:20:12,601 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:23:50,915 [INFO] Averaged stats: loss: 0.620263  acc: 0.651105 ***auc: 0.7194210330082071 ***uauc: 0.6723644554568741 ***u-nDCG: 0.8631489786775967 ***AP@10: 3.043334242655264 ***Coverage@10: 0.3062039312039312 ***Gini@10: 0.3674959223579607 ***DivRatio@10: 0.48848603625673687 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-28 22:23:50,927 [INFO] Saving checkpoint at epoch 7 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251128215\checkpoint_best.pth.
2025-11-28 22:23:51,835 [INFO] Start training
2025-11-28 22:23:51,855 [INFO] Start training epoch 8, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:24:23,054 [INFO] Averaged stats: lr: 0.001000  loss: 0.523068
2025-11-28 22:24:23,056 [INFO] Evaluating on valid.
2025-11-28 22:24:23,060 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:27:59,947 [INFO] Averaged stats: loss: 0.660751  acc: 0.599657 ***auc: 0.7150163206512401 ***uauc: 0.6833268127278772 ***u-nDCG: 0.8701054063949053 ***AP@10: 3.05206301035153 ***Coverage@10: 0.3046683046683047 ***Gini@10: 0.3710694868107032 ***DivRatio@10: 0.48603625673689366 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-28 22:27:59,970 [INFO] Start training
2025-11-28 22:27:59,992 [INFO] Start training epoch 9, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:28:30,390 [INFO] Averaged stats: lr: 0.001000  loss: 0.510453
2025-11-28 22:28:30,392 [INFO] Evaluating on valid.
2025-11-28 22:28:30,401 [WARNING] item_category_dict not provided. MGU metric will be 0.

answer token ids: pos: 9454 neg ids: 2753
Prompt Pos Example 
#Question: A user has given high ratings to the following movies: <ItemTitleList>. Additionally, we have information about the user's preferences encoded in the feature <UserID>. Using all available information, make a prediction about whether the user would enjoy the movie titled <TargetItemTitle> with the feature <TargetItemID>? Answer with "Yes" or "No". \n#Answer: Yes or No
llama_proj.0.weight
llama_proj.0.bias
llama_proj.2.weight
llama_proj.2.bias
prompt example: <s>#Question: A user has given high ratings to the following movies: "Best in Show (2000)", "High Fidelity (2000)", "Bring It On (2000)", "28 Days (2000)", "Perfect Storm, The (2000)", "Return to Me (2000)", "Thomas Crown Affair, The (1999)". Additionally, we have information about the user's preferences encoded in the feature <unk>. Using all available information, make a prediction about whether the user would enjoy the movie titled "My Dog Skip (1999)" with the feature <unk>? Answer with "Yes" or "No". \n#Answer:
#######prmpt decoded example:  <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <s ># Question :  A  user  has  given  high  ratings  to  the  following  movies :  " Dave  ( 1 9 9 3 )",  " Add ams  Family ,  The  ( 1 9 9 1 )",  " Ham let  ( 1 9 9 0 )",  " Cour age  Under  Fire  ( 1 9 9 6 )",  " P ump  Up  the  Volume  ( 1 9 9 0 )",  " B ul worth  ( 1 9 9 8 )",  " M ight y  Aph rod ite  ( 1 9 9 5 )",  " Four  Wed dings  and  a  Funeral  ( 1 9 9 4 )",  " In  the  Name  of  the  Father  ( 1 9 9 3 )",  " S cream  ( 1 9 9 6 )".  Additionally ,  we  have  information  about  the  user 's  preferences  encoded  in  the  feature   <unk> .  Using  all  available  information ,  make  a  prediction  about  whether  the  user  would  enjoy  the  movie  titled  " Last  Sup per ,  The  ( 1 9 9 5 )"  with  the  feature   <unk> ?  Answer  with  " Yes "  or  " No ".  \ n # Answer :
Train: data epoch: [0]  [ 0/50]  eta: 0:00:39  lr: 0.000010  loss: 0.7437  time: 0.7991  data: 0.0000  max mem: 18557
Train: data epoch: [0]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.5879  time: 0.5436  data: 0.0000  max mem: 21199
Train: data epoch: [0] Total time: 0:00:27 (0.5452 s / it)
Evaluation  [ 0/82]  eta: 0:02:14  loss: 0.6341  acc: 0.6562  time: 1.6372  data: 0.0060  max mem: 24751
Evaluation  [16/82]  eta: 0:02:31  loss: 0.7615  acc: 0.5469  time: 2.3008  data: 0.0030  max mem: 29510
Evaluation  [32/82]  eta: 0:01:57  loss: 0.7273  acc: 0.5938  time: 2.3994  data: 0.0028  max mem: 30553
Evaluation  [48/82]  eta: 0:01:20  loss: 0.7352  acc: 0.6875  time: 2.3870  data: 0.0027  max mem: 31643
Evaluation  [64/82]  eta: 0:00:43  loss: 0.6902  acc: 0.6406  time: 2.4387  data: 0.0026  max mem: 31643
Evaluation  [80/82]  eta: 0:00:04  loss: 0.6618  acc: 0.6406  time: 2.3718  data: 0.0023  max mem: 31643
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4484  acc: 0.8750  time: 2.2751  data: 0.0021  max mem: 31643
Evaluation Total time: 0:03:14 (2.3667 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0765829086303711 uauc: 0.6581281859094846
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003045320510864258 u-nDCG: 0.8567996149928117
Metrics @10: AP=3.0367, Cov=0.3059, Gini=0.3694
Advanced @10: DivRatio=0.4880, ORRatio=0.0206, MGU=0.0000
rank_0 auc: 0.6983865993518067
Train: data epoch: [1]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.7799  time: 0.5002  data: 0.0000  max mem: 31643
Train: data epoch: [1]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.3600  time: 0.5304  data: 0.0000  max mem: 31643
Train: data epoch: [1] Total time: 0:00:27 (0.5433 s / it)
Evaluation  [ 0/82]  eta: 0:01:59  loss: 0.6244  acc: 0.6562  time: 1.4566  data: 0.0046  max mem: 31643
Evaluation  [16/82]  eta: 0:02:48  loss: 0.7589  acc: 0.5469  time: 2.5580  data: 0.0062  max mem: 31643
Evaluation  [32/82]  eta: 0:02:14  loss: 0.6947  acc: 0.6094  time: 2.8160  data: 0.0094  max mem: 31643
Evaluation  [48/82]  eta: 0:01:34  loss: 0.7037  acc: 0.6875  time: 2.8737  data: 0.0077  max mem: 31643
Evaluation  [64/82]  eta: 0:00:50  loss: 0.6871  acc: 0.6562  time: 2.8627  data: 0.0100  max mem: 31643
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6580  acc: 0.6250  time: 2.5695  data: 0.0041  max mem: 31643
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4421  acc: 0.8125  time: 2.4610  data: 0.0039  max mem: 31643
Evaluation Total time: 0:03:42 (2.7126 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07585263252258301 uauc: 0.6639749491411188
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0020194053649902344 u-nDCG: 0.8564850575597747
Metrics @10: AP=3.0307, Cov=0.3065, Gini=0.3681
Advanced @10: DivRatio=0.4890, ORRatio=0.0206, MGU=0.0000
rank_0 auc: 0.7063810680148644
Train: data epoch: [2]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.6945  time: 0.5076  data: 0.0000  max mem: 31643
Train: data epoch: [2]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.3801  time: 0.5338  data: 0.0000  max mem: 31643
Train: data epoch: [2] Total time: 0:00:26 (0.5341 s / it)
Evaluation  [ 0/82]  eta: 0:01:59  loss: 0.6185  acc: 0.6250  time: 1.4600  data: 0.0061  max mem: 31643
Evaluation  [16/82]  eta: 0:02:47  loss: 0.6985  acc: 0.5469  time: 2.5447  data: 0.0070  max mem: 31643
Evaluation  [32/82]  eta: 0:02:11  loss: 0.6527  acc: 0.6562  time: 2.7211  data: 0.0064  max mem: 31643
Evaluation  [48/82]  eta: 0:01:31  loss: 0.6507  acc: 0.7031  time: 2.7729  data: 0.0098  max mem: 31643
Evaluation  [64/82]  eta: 0:00:49  loss: 0.6723  acc: 0.6406  time: 2.8282  data: 0.0064  max mem: 31643
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6405  acc: 0.6094  time: 2.7716  data: 0.0089  max mem: 31643
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4329  acc: 0.7500  time: 2.6586  data: 0.0088  max mem: 31643
Evaluation Total time: 0:03:42 (2.7140 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.17116785049438477 uauc: 0.6634068194874201
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007668018341064453 u-nDCG: 0.8563146063055898
Metrics @10: AP=3.0209, Cov=0.3090, Gini=0.3660
Advanced @10: DivRatio=0.4929, ORRatio=0.0196, MGU=0.0000
rank_0 auc: 0.7177403392777041
Train: data epoch: [3]  [ 0/50]  eta: 0:00:31  lr: 0.000010  loss: 0.6678  time: 0.6237  data: 0.0000  max mem: 31643
Train: data epoch: [3]  [49/50]  eta: 0:00:00  lr: 0.000253  loss: 0.5583  time: 0.6175  data: 0.0000  max mem: 31643
Train: data epoch: [3] Total time: 0:00:30 (0.6189 s / it)
Evaluation  [ 0/82]  eta: 0:02:26  loss: 0.6392  acc: 0.5781  time: 1.7873  data: 0.0228  max mem: 31643
Evaluation  [16/82]  eta: 0:02:46  loss: 0.7002  acc: 0.5469  time: 2.5246  data: 0.0051  max mem: 31643
Evaluation  [32/82]  eta: 0:02:12  loss: 0.6119  acc: 0.6094  time: 2.7687  data: 0.0088  max mem: 31643
Evaluation  [48/82]  eta: 0:01:33  loss: 0.6456  acc: 0.5625  time: 2.8755  data: 0.0109  max mem: 31643
Evaluation  [64/82]  eta: 0:00:50  loss: 0.6382  acc: 0.6250  time: 2.9566  data: 0.0078  max mem: 31643
Evaluation  [80/82]  eta: 0:00:05  loss: 0.6405  acc: 0.5312  time: 2.7221  data: 0.0069  max mem: 31643
Evaluation  [81/82]  eta: 0:00:02  loss: 0.4645  acc: 0.7500  time: 2.6163  data: 0.0067  max mem: 31643
Evaluation Total time: 0:03:45 (2.7458 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21532917022705078 uauc: 0.6768867724724239
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007616758346557617 u-nDCG: 0.86469795424305642025-11-28 22:32:10,385 [INFO] Averaged stats: loss: 0.618976  acc: 0.629764 ***auc: 0.7193283045662335 ***uauc: 0.6734574920724927 ***u-nDCG: 0.8621627758295921 ***AP@10: 3.045225211204823 ***Coverage@10: 0.3068181818181818 ***Gini@10: 0.3697087582437901 ***DivRatio@10: 0.4894659480646742 ***ORRatio@10: 0.020088192062714356 ***MGU@10: 0.0
2025-11-28 22:32:10,400 [INFO] Start training
2025-11-28 22:32:10,418 [INFO] Start training epoch 10, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:32:37,084 [INFO] Averaged stats: lr: 0.001000  loss: 0.480222
2025-11-28 22:32:37,085 [INFO] Evaluating on valid.
2025-11-28 22:32:37,090 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:36:16,874 [INFO] Averaged stats: loss: 0.636884  acc: 0.628811 ***auc: 0.7146108100427055 ***uauc: 0.678781614712052 ***u-nDCG: 0.864014409931385 ***AP@10: 3.014483096101776 ***Coverage@10: 0.3108108108108108 ***Gini@10: 0.3597477017582251 ***DivRatio@10: 0.49583537481626655 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-28 22:36:16,890 [INFO] Start training
2025-11-28 22:36:16,905 [INFO] Start training epoch 11, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:36:48,136 [INFO] Averaged stats: lr: 0.001000  loss: 0.493997
2025-11-28 22:36:48,137 [INFO] Evaluating on valid.
2025-11-28 22:36:48,153 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:40:22,901 [INFO] Averaged stats: loss: 0.636553  acc: 0.642721 ***auc: 0.7146067267246043 ***uauc: 0.6799084958385642 ***u-nDCG: 0.863866513712567 ***AP@10: 3.034878009975963 ***Coverage@10: 0.3071253071253071 ***Gini@10: 0.3640754532092112 ***DivRatio@10: 0.4899559039686428 ***ORRatio@10: 0.020578147966683 ***MGU@10: 0.0
2025-11-28 22:40:22,907 [INFO] Start training
2025-11-28 22:40:22,915 [INFO] Start training epoch 12, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:40:49,783 [INFO] Averaged stats: lr: 0.001000  loss: 0.487399
2025-11-28 22:40:49,785 [INFO] Evaluating on valid.
2025-11-28 22:40:49,790 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:44:35,948 [INFO] Averaged stats: loss: 0.645568  acc: 0.614139 ***auc: 0.7146547613939052 ***uauc: 0.685491611821648 ***u-nDCG: 0.8708116008093006 ***AP@10: 3.055715613419543 ***Coverage@10: 0.3025184275184275 ***Gini@10: 0.3695585671401248 ***DivRatio@10: 0.4826065654091132 ***ORRatio@10: 0.01910828025477707 ***MGU@10: 0.0
2025-11-28 22:44:35,965 [INFO] Start training
2025-11-28 22:44:35,982 [INFO] Start training epoch 13, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:45:06,137 [INFO] Averaged stats: lr: 0.001000  loss: 0.542995
2025-11-28 22:45:06,138 [INFO] Evaluating on valid.
2025-11-28 22:45:06,142 [WARNING] item_category_dict not provided. MGU metric will be 0.
2025-11-28 22:48:42,539 [INFO] Averaged stats: loss: 0.621274  acc: 0.666921 ***auc: 0.7252360491952226 ***uauc: 0.682474589092256 ***u-nDCG: 0.864719987423275 ***AP@10: 3.0309650138899356 ***Coverage@10: 0.30405405405405406 ***Gini@10: 0.3669106548087441 ***DivRatio@10: 0.4850563449289564 ***ORRatio@10: 0.019598236158745713 ***MGU@10: 0.0
2025-11-28 22:48:42,553 [INFO] Saving checkpoint at epoch 13 to D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251128215\checkpoint_best.pth.
2025-11-28 22:48:43,355 [INFO] Start training
2025-11-28 22:48:43,372 [INFO] Start training epoch 14, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-article\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-28 22:49:23,762 [INFO] Averaged stats: lr: 0.000999  loss: 0.500437
2025-11-28 22:49:23,765 [INFO] Evaluating on valid.
2025-11-28 22:49:23,776 [WARNING] item_category_dict not provided. MGU metric will be 0.
